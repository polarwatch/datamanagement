[
  {
    "objectID": "ai-ready-data-checklist-v.1.0.html",
    "href": "ai-ready-data-checklist-v.1.0.html",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "source: https://github.com/ESIPFed/data-readiness/blob/main/checklist-published/ai-ready-data-checklist-v.1.0.md\nThe checklist is developed using the 2019 draft readiness matrix developed by the Office of Science and Technology Policy Subcommittee on Open Science as a basis. The checklist has been improved based on further research and user feedback. Definitions for some concepts are listed at the end of this document. This checklist is developed through a collaboration of ESIP Data Readiness Cluster members include representatives from NOAA, NASA, USGS, and other organizations. The checklist will be updated periodically to reflect community feedback.\nLink to the google sheet\n\n\nIdeally for AI-ready assessment, a dataset should be defined as the minimum measurable bundle (i.e., a physical parameter/variable of observational datasets or model simulations). The assessment at this scale will enable better integration of data from different sources for research and development. However, it can be an intensive process for manual assessment without automation. Therefore, we recommend current assessments be done on the data file level. If the dataset has different versions, the checklist should be applied to each dataset type (e.g. raw, derived).\n\n\n\n\nESIP Data Readiness Cluster (2023): Checklist to Examine AI-readiness for Open Environmental Datasets v.1.0. ESIP. Online resource. https://doi.org/10.6084/m9.figshare.19983722.v1\n\n\n\n\nVersion: 1.0;\nLast updated: June 21, 2023.\n\n\n\n\n\nLink to the dataset landing page (questions below could be automatically filled from the landing page in the future)\n\nName of the dataset\nThe current version of the dataset\nPoint of contact for the dataset\nWhen was the dataset originally published?\n\nIs this raw data or a derived/processed data product? Raw/Derived\nIs this observational data, simulation/model output, or synthetic data? Observed/Modeled/Synthetic\nIs the data single-source or aggregated from several sources? Single-source/Aggregated\n\n\n\n\n\nQuestions on timeliness:\n\nWill the dataset be updated? Yes, it will be updated. / No, it will not be updated\nIf the data will be updated, how often will it be updated? [choose from]\n\nUpdated when new data are added.\n\nChoose the update frequency that best describes the dataset: near-real-time (irregularly) / hourly or sub-hourly / daily or sub-daily / weekly / monthly / yearly / longer than a year\nWill there be different stages of the update (e.g., updated with preliminary data first and replaced by a later update of the full record)? Yes/No/Not applicable.\n\nIf yes, what is the delay between different stages? [short answer]\n\n\nUpdated when a new version of the dataset is available.\n\nShould the new version of the dataset supersede the current version? Yes / No / Others\n\nProvide an explanation for “Others”\n\n\n\n\nQuestions on data completeness\n\nIs there any documentation about the completeness of the dataset? Yes / No\n\nIf yes, link to the report/document\n\nHow complete is the dataset compared to the expected spatial coverage? Complete / Partial / Unknown / Not applicable\nHow complete is the dataset compared to the expected temporal coverage? Complete / Partial / Unknown / Not applicable\n\nQuestions on data consistency\n\nIs this dataset self-consistent in that its units, data types, and parameter names do not change over time and space? Yes / No / Not applicable\nIs this dataset’s units, data types, and parameter names consistent with similar data collections? Yes / No / Not applicable\nAre there processes to monitor for units, data types, and parameter consistency? Yes / No / Not applicable\n\nIf yes, what measures are taken? Manual review / Automated review\n\n\nQuestions on data bias\n\nIs there known bias in the dataset? Yes / No\n\nIf yes, provide more information\n\nHave measures been taken to examine bias? Yes / No\n\nIf yes, what measures were used?\nIs the bias metrological traceable?\n\nIs there reported bias in the data? No known bias / Bias found and reported / No information available\n\n(optional) Link to the report/document on the bias\n(optional) Link to tools available to reduce bias\n(optional) Link to a bias-corrected or bias-reduced version of the dataset\n\nIs there quantitative information about data resolution in space and time? Yes / No / Not applicable\nAre there published data quality procedures or reports? Yes / No\n\nIf there is published quality information, please provide the link to the information.\n\nIs the provenance of the dataset tracked and documented? Yes / No / Not applicable\nAre there checksums / other checks for data integrity? Yes / No / Not applicable\nWhat is the size of the dataset? Depending on the resource, this might be total data volume, dimensionality, number of images, data files, table rows, image size, etc. [Short Answer]\n\n\n\n\n\n\nDoes the dataset metadata follow a community/domain standard or convention? Yes / No / Not applicable\n\nIf the metadata follows a community/domain standard, which standard is it? Select from a list [CF, …, TBD, others]\nIs the dataset metadata machine-readable? Yes / No / Not applicable\nDoes it include details on the spatial and temporal extent? Yes / No / Not applicable\n\nIs there a comprehensive data dictionary/codebook that describes what each element of the dataset means? parameters? Yes / No / Not applicable\n\nIs the data dictionary standardized? Yes / No / Not applicable\nIs the data dictionary machine-readable? Yes / No / Not applicable\nDo the parameters follow a defined standard? Yes / No / Not applicable\n\nIf the parameters follow a defined standard, which standard it is?\n\nAre parameters crosswalked in an ontology or common vocabulary (e.g. NIEM)? Yes / No / Not applicable\n\nDoes the dataset have a unique persistent identifier, e.g. DOI? Yes, [supply identifier] / No / Not applicable\nIs there contact information for subject-matter experts? Yes / No / Not applicable\nIs there a mechanism for user feedback and suggestions? Yes / No / Not applicable\nAre there example codes/notebooks/toolkits available showing how the data can be used? Yes / No / Not applicable\nWhat is the license for the data?\n\nPick from a list of data licenses + others + no official data license\nIs the license standardized and machine-readable (e.g. Creative Commons)? Yes / No / Not applicable\n\nHas this dataset already been used in AI or ML activities? Link to publications/reports.\nAre there recommendations on the intended use of the data, and uses that are not recommended? Yes / No/ Not applicable\n\n\n\n\n\nWhat is/are the major file formats? Pick from a list of common data formats/ “other” (choose all that apply)\n\nIs this format machine-readable? Yes / No / Not applicable\nIs the data available in at least one open, non-proprietary format? Yes / No / Not applicable\nAre there tools/services to support data format conversion? Yes / No\n\nIf so, provide the link to the tools/services\n\n\nData delivery:\n\nDoes data access require authentication (e.g., a registered user account)? Yes / No / Not applicable\nCan the file be accessed via direct file downloading or ordering? Yes / No / Not applicable\nIs there an Application Programming Interface (API) or web service to access the data? Yes / No / Not applicable\nIf there is an API, does the API follow an open standard protocol (e.g., OGC)? Yes / No\nIf there is an API, is there documentation for the API? Yes / No\n\nIf “Yes”, please provide a URL to the documentation.\n\nIs the data available publicly via cloud services? Yes / No / Not applicable\n\nFor restricted data, have measures been taken to provide some access while still applying appropriate protection for privacy and security? Yes / No / Not Applicable\n\nHas the data been aggregated to reduce granularity? Yes / No / Not applicable\nHas the data been anonymized / de-identified? Yes / No / Not applicable\nIs there secure access to the full dataset for authorized users? Yes / No / Not applicable\n\n\n\n\n\n\nHave null values/gaps been filled? Yes / No / Not applicable\nHave outliers been identified? Yes, tagged / Yes, removed / No / Not applicable\nIs the data gridded (regularly sampled in time and space)?\n\nOptions to choose from (choose all that apply):\n\nRegularly gridded in space / Constant time-frequency / Regularly gridded in space and constant time-frequency / Not gridded / Not applicable\n\nIf the data is gridded, was it transformed from a different original sampling? Yes, from irregular sampling / Yes, from a different regular sampling / No, this is the original sampling\nIf the data is resampled from the original sampling, is the data also available at the original sampling? Yes / No / Only available at request / Not applicable\n\nAre there associated targets or labels for supervised learning techniques (i.e., can this be used as a training dataset for supervised learning techniques)? Yes / No / Not applicable\n\nIf there are associated targets/labels, are community labeling standards implemented (e.g., STAC label extension, ESA AIREO specification, etc)?\n\nA list of label standards to choose from + “others” option\n\n\n\n\n\n\n\n\n\n\nCompleteness: the breadth of a dataset compared to an ideal 100% completion (spatial, temporal, demographic, etc.); important in avoiding sampling bias\nConsistency: uniformity within the entire dataset or compared with similar data collections; for example, no changes in units or data types over time; the item measured against itself or its a counterpart in another dataset or database\nBias: a systematic tilt in the dataset when compared to a reference, caused for example by instrumentation, incorrect data processing, unrepresentative sampling, or human error; the exact nature of bias and how it is measured will vary depending on the type of data and the research domain.\nUncertainty: parameter, associated with the result of a measurement, that characterizes the dispersion of the values that could reasonably be attributed to the measurand.\nTimeliness: the speed of data release, compared to when an event occurred or measurements were made; requirements will vary depending on the timeframe of the phenomenon (e.g., severe thunderstorms vs. climate change, or disease outbreaks vs. life expectancy trends)\nProvenance: identification of the data sources, how it was processed, and who released it.\nIntegrity: verification that the data remains unchanged from the original; aka data fixity.\n\n\n\n\n\nDataset Metadata: complete information about the dataset: quality, provenance, location, time period, responsible parties, purpose, etc.\nData Dictionary/Codebook: complete information about the individual variables / measures / parameters within a dataset: type, units, null value, etc.\nIdentifier: a code or number that uniquely identifies a dataset\nOntology: formalized definitions of concepts within a domain of knowledge, and the nature of the inter-relationships among those concepts\n\n\n\n\n\nFormats: standards that govern how information is stored in a computer file (e.g., CSV, JSON, GeoTIFF, etc.); different AI user communities will have different requirements, so the best practice is to provide several format options to meet the needs of multiple high priority user communities.\nDelivery Options: mechanisms for publishing open data for public use (e.g., direct file download, Application Programming Interface (API), cloud services, etc.); different AI user communities will have different requirements, so the best practice is to provide several delivery options to meet the needs of multiple high priority user communities.\nLicense/Usage Rights: information on who is allowed to use the data and for what purposes, including data sharing agreements, fees, etc.; some federal data needs to have restrictions and some will be fully open, so rights should be documented in detail\nSecurity/Privacy: protection of data that is restricted in some way (privacy, proprietary/business information, national security, etc.)\n\n\n\n\n\n\nOSTP Subcommittee on Open Science (2019), Draft AI-ready data matrix. (This draft document is not an official publication of the committee and can be requested for reference.)"
  },
  {
    "objectID": "ai-ready-data-checklist-v.1.0.html#general-information",
    "href": "ai-ready-data-checklist-v.1.0.html#general-information",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "Link to the dataset landing page (questions below could be automatically filled from the landing page in the future)\n\nName of the dataset\nThe current version of the dataset\nPoint of contact for the dataset\nWhen was the dataset originally published?\n\nIs this raw data or a derived/processed data product? Raw/Derived\nIs this observational data, simulation/model output, or synthetic data? Observed/Modeled/Synthetic\nIs the data single-source or aggregated from several sources? Single-source/Aggregated"
  },
  {
    "objectID": "ai-ready-data-checklist-v.1.0.html#data-quality",
    "href": "ai-ready-data-checklist-v.1.0.html#data-quality",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "Questions on timeliness:\n\nWill the dataset be updated? Yes, it will be updated. / No, it will not be updated\nIf the data will be updated, how often will it be updated? [choose from]\n\nUpdated when new data are added.\n\nChoose the update frequency that best describes the dataset: near-real-time (irregularly) / hourly or sub-hourly / daily or sub-daily / weekly / monthly / yearly / longer than a year\nWill there be different stages of the update (e.g., updated with preliminary data first and replaced by a later update of the full record)? Yes/No/Not applicable.\n\nIf yes, what is the delay between different stages? [short answer]\n\n\nUpdated when a new version of the dataset is available.\n\nShould the new version of the dataset supersede the current version? Yes / No / Others\n\nProvide an explanation for “Others”\n\n\n\n\nQuestions on data completeness\n\nIs there any documentation about the completeness of the dataset? Yes / No\n\nIf yes, link to the report/document\n\nHow complete is the dataset compared to the expected spatial coverage? Complete / Partial / Unknown / Not applicable\nHow complete is the dataset compared to the expected temporal coverage? Complete / Partial / Unknown / Not applicable\n\nQuestions on data consistency\n\nIs this dataset self-consistent in that its units, data types, and parameter names do not change over time and space? Yes / No / Not applicable\nIs this dataset’s units, data types, and parameter names consistent with similar data collections? Yes / No / Not applicable\nAre there processes to monitor for units, data types, and parameter consistency? Yes / No / Not applicable\n\nIf yes, what measures are taken? Manual review / Automated review\n\n\nQuestions on data bias\n\nIs there known bias in the dataset? Yes / No\n\nIf yes, provide more information\n\nHave measures been taken to examine bias? Yes / No\n\nIf yes, what measures were used?\nIs the bias metrological traceable?\n\nIs there reported bias in the data? No known bias / Bias found and reported / No information available\n\n(optional) Link to the report/document on the bias\n(optional) Link to tools available to reduce bias\n(optional) Link to a bias-corrected or bias-reduced version of the dataset\n\nIs there quantitative information about data resolution in space and time? Yes / No / Not applicable\nAre there published data quality procedures or reports? Yes / No\n\nIf there is published quality information, please provide the link to the information.\n\nIs the provenance of the dataset tracked and documented? Yes / No / Not applicable\nAre there checksums / other checks for data integrity? Yes / No / Not applicable\nWhat is the size of the dataset? Depending on the resource, this might be total data volume, dimensionality, number of images, data files, table rows, image size, etc. [Short Answer]"
  },
  {
    "objectID": "ai-ready-data-checklist-v.1.0.html#data-documentation",
    "href": "ai-ready-data-checklist-v.1.0.html#data-documentation",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "Does the dataset metadata follow a community/domain standard or convention? Yes / No / Not applicable\n\nIf the metadata follows a community/domain standard, which standard is it? Select from a list [CF, …, TBD, others]\nIs the dataset metadata machine-readable? Yes / No / Not applicable\nDoes it include details on the spatial and temporal extent? Yes / No / Not applicable\n\nIs there a comprehensive data dictionary/codebook that describes what each element of the dataset means? parameters? Yes / No / Not applicable\n\nIs the data dictionary standardized? Yes / No / Not applicable\nIs the data dictionary machine-readable? Yes / No / Not applicable\nDo the parameters follow a defined standard? Yes / No / Not applicable\n\nIf the parameters follow a defined standard, which standard it is?\n\nAre parameters crosswalked in an ontology or common vocabulary (e.g. NIEM)? Yes / No / Not applicable\n\nDoes the dataset have a unique persistent identifier, e.g. DOI? Yes, [supply identifier] / No / Not applicable\nIs there contact information for subject-matter experts? Yes / No / Not applicable\nIs there a mechanism for user feedback and suggestions? Yes / No / Not applicable\nAre there example codes/notebooks/toolkits available showing how the data can be used? Yes / No / Not applicable\nWhat is the license for the data?\n\nPick from a list of data licenses + others + no official data license\nIs the license standardized and machine-readable (e.g. Creative Commons)? Yes / No / Not applicable\n\nHas this dataset already been used in AI or ML activities? Link to publications/reports.\nAre there recommendations on the intended use of the data, and uses that are not recommended? Yes / No/ Not applicable"
  },
  {
    "objectID": "ai-ready-data-checklist-v.1.0.html#data-access",
    "href": "ai-ready-data-checklist-v.1.0.html#data-access",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "What is/are the major file formats? Pick from a list of common data formats/ “other” (choose all that apply)\n\nIs this format machine-readable? Yes / No / Not applicable\nIs the data available in at least one open, non-proprietary format? Yes / No / Not applicable\nAre there tools/services to support data format conversion? Yes / No\n\nIf so, provide the link to the tools/services\n\n\nData delivery:\n\nDoes data access require authentication (e.g., a registered user account)? Yes / No / Not applicable\nCan the file be accessed via direct file downloading or ordering? Yes / No / Not applicable\nIs there an Application Programming Interface (API) or web service to access the data? Yes / No / Not applicable\nIf there is an API, does the API follow an open standard protocol (e.g., OGC)? Yes / No\nIf there is an API, is there documentation for the API? Yes / No\n\nIf “Yes”, please provide a URL to the documentation.\n\nIs the data available publicly via cloud services? Yes / No / Not applicable\n\nFor restricted data, have measures been taken to provide some access while still applying appropriate protection for privacy and security? Yes / No / Not Applicable\n\nHas the data been aggregated to reduce granularity? Yes / No / Not applicable\nHas the data been anonymized / de-identified? Yes / No / Not applicable\nIs there secure access to the full dataset for authorized users? Yes / No / Not applicable"
  },
  {
    "objectID": "ai-ready-data-checklist-v.1.0.html#data-preparation",
    "href": "ai-ready-data-checklist-v.1.0.html#data-preparation",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "Have null values/gaps been filled? Yes / No / Not applicable\nHave outliers been identified? Yes, tagged / Yes, removed / No / Not applicable\nIs the data gridded (regularly sampled in time and space)?\n\nOptions to choose from (choose all that apply):\n\nRegularly gridded in space / Constant time-frequency / Regularly gridded in space and constant time-frequency / Not gridded / Not applicable\n\nIf the data is gridded, was it transformed from a different original sampling? Yes, from irregular sampling / Yes, from a different regular sampling / No, this is the original sampling\nIf the data is resampled from the original sampling, is the data also available at the original sampling? Yes / No / Only available at request / Not applicable\n\nAre there associated targets or labels for supervised learning techniques (i.e., can this be used as a training dataset for supervised learning techniques)? Yes / No / Not applicable\n\nIf there are associated targets/labels, are community labeling standards implemented (e.g., STAC label extension, ESA AIREO specification, etc)?\n\nA list of label standards to choose from + “others” option"
  },
  {
    "objectID": "ai-ready-data-checklist-v.1.0.html#appendix---definition-of-terms-used-in-the-checklist",
    "href": "ai-ready-data-checklist-v.1.0.html#appendix---definition-of-terms-used-in-the-checklist",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "Completeness: the breadth of a dataset compared to an ideal 100% completion (spatial, temporal, demographic, etc.); important in avoiding sampling bias\nConsistency: uniformity within the entire dataset or compared with similar data collections; for example, no changes in units or data types over time; the item measured against itself or its a counterpart in another dataset or database\nBias: a systematic tilt in the dataset when compared to a reference, caused for example by instrumentation, incorrect data processing, unrepresentative sampling, or human error; the exact nature of bias and how it is measured will vary depending on the type of data and the research domain.\nUncertainty: parameter, associated with the result of a measurement, that characterizes the dispersion of the values that could reasonably be attributed to the measurand.\nTimeliness: the speed of data release, compared to when an event occurred or measurements were made; requirements will vary depending on the timeframe of the phenomenon (e.g., severe thunderstorms vs. climate change, or disease outbreaks vs. life expectancy trends)\nProvenance: identification of the data sources, how it was processed, and who released it.\nIntegrity: verification that the data remains unchanged from the original; aka data fixity.\n\n\n\n\n\nDataset Metadata: complete information about the dataset: quality, provenance, location, time period, responsible parties, purpose, etc.\nData Dictionary/Codebook: complete information about the individual variables / measures / parameters within a dataset: type, units, null value, etc.\nIdentifier: a code or number that uniquely identifies a dataset\nOntology: formalized definitions of concepts within a domain of knowledge, and the nature of the inter-relationships among those concepts\n\n\n\n\n\nFormats: standards that govern how information is stored in a computer file (e.g., CSV, JSON, GeoTIFF, etc.); different AI user communities will have different requirements, so the best practice is to provide several format options to meet the needs of multiple high priority user communities.\nDelivery Options: mechanisms for publishing open data for public use (e.g., direct file download, Application Programming Interface (API), cloud services, etc.); different AI user communities will have different requirements, so the best practice is to provide several delivery options to meet the needs of multiple high priority user communities.\nLicense/Usage Rights: information on who is allowed to use the data and for what purposes, including data sharing agreements, fees, etc.; some federal data needs to have restrictions and some will be fully open, so rights should be documented in detail\nSecurity/Privacy: protection of data that is restricted in some way (privacy, proprietary/business information, national security, etc.)"
  },
  {
    "objectID": "ai-ready-data-checklist-v.1.0.html#references",
    "href": "ai-ready-data-checklist-v.1.0.html#references",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "OSTP Subcommittee on Open Science (2019), Draft AI-ready data matrix. (This draft document is not an official publication of the committee and can be requested for reference.)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "datasets/dmp/nesdis_blendedsic_nhem_daily.html",
    "href": "datasets/dmp/nesdis_blendedsic_nhem_daily.html",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Not for use\n\n\n\nThis document is a working copy and not intended for use.\n\n\n\n\nThis dataset represents the 1km Blended sea ice concentration for the Arctic, utilizing data from the AMSR2 instrument aboard the GCOM-W1 satellite and VIIRS instrument on NOAA-21. The daily sea ice concentration values are stored in the 1 km EASE2-Grid format.\nThese data products are developed through a collaboration between NESDIS and the University of Wisconsin. For more information on the algorithm development, you can visit the provided link: Algorithm Development.\nThe data file, available in NetCDF format, is generated daily with a 2-day delay for data availability. For instance, the data file for February 10, 2024, becomes accessible on February 12, 2024. File sizes vary approximately between 15MB and 360MB, and specific file sizes can be checked on the ERDDAP file page.\nDistribution of the data files is managed through PolarWatch ERDDAP, where they can also be previewed in the PolarWatch Catalog.\n\n\n\n\n\n\ndisclaimer\n\n\n\nPolarWatch ERDDAP enables data subsetting and downloading in various formats through the Data Download Form. However, please note that this dataset is provided in EASE-2 (EPSG:6931) coordinates. For optimal results, direct file downloads from ERDDAP File page are strongly recommended.\n\n\n\n\n\nDaily processing is automated and scheduled to run daily to check, download, compress and store and backup newly created netcdf file from the FTP server.\n\n\n\n\n\nflowchart LR\n  A(File on FTP Server) --&gt;B(File Download to PolarWatch)\n  B --&gt; C(Compressed, Stored, Backed up)\n  C --&gt; D(Accessible on ERDDAP, Catalog)\n\n\n\n\n\n\n\nPolarWatch checks and downloads daily netcdf file from NESDIS/Univ of Wisconin daily (scheduled cron job)\nPolarWatch compresses netcdf file and store on a data server to be accessible\nPolarWatch backsup data file\n\n\n\n\nPolarWatch provides extensive metadata on ERDDAP in addition to embedded metadata in NetCDF. The metadata standard used is CF-16, and both ERDDAP metadata and NetCDF metadata are machine readable.\nThe metadata was created by the data product developer with the template/guidelines provided by PolarWatch. link to template\nERDDAP metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_nhem_daily/index.html\n\n\n\n\n\n\nProjection attributes\n\n\n\nFor software readable projection information is stored in the following attributes srid, proj4text, grid_mapping , grid_mapping_epsg_code: 6931.\n\n\n\n\n\nData are stored in directory on the PolarWatch data server and ERDDAP points to the directory. Data are automatically backed up on a PolarWatch backup server.\nIn the case of the event of an accident, the recovery will be handled by PolarWatch team.\n\n\n\nData are publically accessible without authentication. ERDDAP is the primary data distribution system with a web interface.\nPolarWatch Catalog has a list of data products users can search and view. Users can visit the catalog to search for the data product.\n\nUsers can go to the ERDDAP Webpage to preview, subset data to download or just download the files.\nUsers can use ERDDAP RESTful web services for software to access data.\nTutorials and code samples are available to access data and metadata in commonly used languages (i.e. R, Python)\n\n\n\n\n\n\n\nNote\n\n\n\nCHECK FOR STANDARD LICENSE\n\n\n\n\n\nThis section should cover your long-term strategy for preserving the data produced during your project. See section on data archiving.\n\nWhat data will be preserved for the long-term?\nWhat is the long-term strategy for maintaining, curating and archiving the data?\nWhere will it be preserved?\nWhich archive/repository/database have you identified as a place to deposit data?\nWhat procedures does your intended long-term data storage facility have in place for preservation and backup?\nHow long will/should data be kept beyond the life of the project?\nData transformations/formats needed\nWhat transformations will be necessary to prepare data for preservation / data sharing?\nWhat metadata/ documentation will be submitted alongside the data or created on deposit/ transformation in order to make the data reusable?\nWhat related information will be deposited?\n\n\n\n\n\n\n\nTODO\n\n\n\nThis is a good discussion topic\n\n\n\n\n\n\nThe PolarWatch Operations Manager is tasked with the implementation, documentation, and periodic updating of the Data Management Plan.\nThe data workflow is designed to be automated. This process is closely monitored, with automatic notifications being sent out in the event of any errors. [TODO: Further details or steps to be added].\nThe documentation for internal data processing is accessible internally, ensuring that relevant team members can access it as needed. Additionally, all scripts associated with this processing are stored in a private repository.\n\n\n\n\n\n\n\nTODO\n\n\n\n\nImplement QC (readin metadata and check for attributes?)\nCheck failure and notify ops manager?\nAdd more info about projection attributes in metadata section"
  },
  {
    "objectID": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#data-description",
    "href": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#data-description",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "This dataset represents the 1km Blended sea ice concentration for the Arctic, utilizing data from the AMSR2 instrument aboard the GCOM-W1 satellite and VIIRS instrument on NOAA-21. The daily sea ice concentration values are stored in the 1 km EASE2-Grid format.\nThese data products are developed through a collaboration between NESDIS and the University of Wisconsin. For more information on the algorithm development, you can visit the provided link: Algorithm Development.\nThe data file, available in NetCDF format, is generated daily with a 2-day delay for data availability. For instance, the data file for February 10, 2024, becomes accessible on February 12, 2024. File sizes vary approximately between 15MB and 360MB, and specific file sizes can be checked on the ERDDAP file page.\nDistribution of the data files is managed through PolarWatch ERDDAP, where they can also be previewed in the PolarWatch Catalog.\n\n\n\n\n\n\ndisclaimer\n\n\n\nPolarWatch ERDDAP enables data subsetting and downloading in various formats through the Data Download Form. However, please note that this dataset is provided in EASE-2 (EPSG:6931) coordinates. For optimal results, direct file downloads from ERDDAP File page are strongly recommended."
  },
  {
    "objectID": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#process-description",
    "href": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#process-description",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Daily processing is automated and scheduled to run daily to check, download, compress and store and backup newly created netcdf file from the FTP server.\n\n\n\n\n\nflowchart LR\n  A(File on FTP Server) --&gt;B(File Download to PolarWatch)\n  B --&gt; C(Compressed, Stored, Backed up)\n  C --&gt; D(Accessible on ERDDAP, Catalog)\n\n\n\n\n\n\n\nPolarWatch checks and downloads daily netcdf file from NESDIS/Univ of Wisconin daily (scheduled cron job)\nPolarWatch compresses netcdf file and store on a data server to be accessible\nPolarWatch backsup data file"
  },
  {
    "objectID": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#metadata",
    "href": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#metadata",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "PolarWatch provides extensive metadata on ERDDAP in addition to embedded metadata in NetCDF. The metadata standard used is CF-16, and both ERDDAP metadata and NetCDF metadata are machine readable.\nThe metadata was created by the data product developer with the template/guidelines provided by PolarWatch. link to template\nERDDAP metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_nhem_daily/index.html\n\n\n\n\n\n\nProjection attributes\n\n\n\nFor software readable projection information is stored in the following attributes srid, proj4text, grid_mapping , grid_mapping_epsg_code: 6931."
  },
  {
    "objectID": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#storage-and-backup",
    "href": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#storage-and-backup",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Data are stored in directory on the PolarWatch data server and ERDDAP points to the directory. Data are automatically backed up on a PolarWatch backup server.\nIn the case of the event of an accident, the recovery will be handled by PolarWatch team."
  },
  {
    "objectID": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#policies-for-access-and-sharing",
    "href": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#policies-for-access-and-sharing",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Data are publically accessible without authentication. ERDDAP is the primary data distribution system with a web interface.\nPolarWatch Catalog has a list of data products users can search and view. Users can visit the catalog to search for the data product.\n\nUsers can go to the ERDDAP Webpage to preview, subset data to download or just download the files.\nUsers can use ERDDAP RESTful web services for software to access data.\nTutorials and code samples are available to access data and metadata in commonly used languages (i.e. R, Python)\n\n\n\n\n\n\n\nNote\n\n\n\nCHECK FOR STANDARD LICENSE"
  },
  {
    "objectID": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#plans-for-archiving-data-samples-and-other-research-products-and-for-preservation-of-access-to-them",
    "href": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#plans-for-archiving-data-samples-and-other-research-products-and-for-preservation-of-access-to-them",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "This section should cover your long-term strategy for preserving the data produced during your project. See section on data archiving.\n\nWhat data will be preserved for the long-term?\nWhat is the long-term strategy for maintaining, curating and archiving the data?\nWhere will it be preserved?\nWhich archive/repository/database have you identified as a place to deposit data?\nWhat procedures does your intended long-term data storage facility have in place for preservation and backup?\nHow long will/should data be kept beyond the life of the project?\nData transformations/formats needed\nWhat transformations will be necessary to prepare data for preservation / data sharing?\nWhat metadata/ documentation will be submitted alongside the data or created on deposit/ transformation in order to make the data reusable?\nWhat related information will be deposited?\n\n\n\n\n\n\n\nTODO\n\n\n\nThis is a good discussion topic"
  },
  {
    "objectID": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#roles-and-responsibilities",
    "href": "datasets/dmp/nesdis_blendedsic_nhem_daily.html#roles-and-responsibilities",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "The PolarWatch Operations Manager is tasked with the implementation, documentation, and periodic updating of the Data Management Plan.\nThe data workflow is designed to be automated. This process is closely monitored, with automatic notifications being sent out in the event of any errors. [TODO: Further details or steps to be added].\nThe documentation for internal data processing is accessible internally, ensuring that relevant team members can access it as needed. Additionally, all scripts associated with this processing are stored in a private repository.\n\n\n\n\n\n\n\nTODO\n\n\n\n\nImplement QC (readin metadata and check for attributes?)\nCheck failure and notify ops manager?\nAdd more info about projection attributes in metadata section"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html",
    "href": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html",
    "title": "PolarWatch Data Management",
    "section": "",
    "text": "Link to Data Landing Page\n\nName : Blended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Antarctic\nVersion : 1.0\nContact : Richard Dworak\nData Published : 12/18/2023\n\nIs this raw data or a derived/processed data product? Derived\nIs this observational data, simulation/model output, or synthetic data? Synthetic\nIs the data single-source or aggregated from several sources? Aggregated"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#general-information",
    "href": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#general-information",
    "title": "PolarWatch Data Management",
    "section": "",
    "text": "Link to Data Landing Page\n\nName : Blended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Antarctic\nVersion : 1.0\nContact : Richard Dworak\nData Published : 12/18/2023\n\nIs this raw data or a derived/processed data product? Derived\nIs this observational data, simulation/model output, or synthetic data? Synthetic\nIs the data single-source or aggregated from several sources? Aggregated"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#data-quality",
    "href": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#data-quality",
    "title": "PolarWatch Data Management",
    "section": "Data Quality",
    "text": "Data Quality\n\nTimeliness:\n\nWill the dataset be updated? Yes, it will be updated. \n\nUpdated when new data are added daily\nWill there be different stages of the update? No\n\n\nData completeness\n\nIs there any documentation about the completeness of the dataset? Yes\n\nlink to documentation\n\nHow complete is the dataset compared to the expected spatial coverage? Complete\nHow complete is the dataset compared to the expected temporal coverage? Complete\n\nData consistency\n\nIs this dataset self-consistent in that its units, data types, and parameter names do not change over time and space? Yes\nIs this dataset’s units, data types, and parameter names consistent with similar data collections? Yes\nAre there processes to monitor for units, data types, and parameter consistency? No\n\nIf yes, what measures are taken? Manual review [TODO]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nCheck for pole hole, flag values?\nData consistency: create data management plan and add review process\n\n\n\n\nData bias\n\nIs there known bias in the dataset? No\n\nlink to documentation\n\nHave measures been taken to examine bias? No\nIs there reported bias in the data? No known bias\nIs there quantitative information about data resolution in space and time? Yes\nAre there published data quality procedures or reports? No\nIs the provenance of the dataset tracked and documented? No\nAre there checksums / other checks for data integrity? No\nWhat is the size of the dataset? Depending on the resource, this might be total data volume, dimensionality, number of images, data files, table rows, image size, etc. _ approximately 15 ~ 540 MB (file size per day)_"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#data-documentation",
    "href": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#data-documentation",
    "title": "PolarWatch Data Management",
    "section": "Data Documentation",
    "text": "Data Documentation\n\nDoes the dataset metadata follow a community/domain standard or convention? Yes\n\nIf the metadata follows a community/domain standard, which standard is it? CF-1.6, ACDD-1.3, NOAA CDR v1.0, GDS v2.0, COARDS\nIs the dataset metadata machine-readable? Yes\nDoes it include details on the spatial and temporal extent? Yes\n\nIs there a comprehensive data dictionary/codebook that describes what each element of the dataset means? parameters? Yes\n\nIs the data dictionary standardized? Yes\nIs the data dictionary machine-readable? Yes\nDo the parameters follow a defined standard? Yes\n\nIf the parameters follow a defined standard, which standard it is? CF-1.6\n\nAre parameters crosswalked in an ontology or common vocabulary (e.g. NIEM)? Not applicable\n\nDoes the dataset have a unique persistent identifier, e.g. DOI? Yes (CHECK DOI)\nIs there contact information for subject-matter experts? Yes\nIs there a mechanism for user feedback and suggestions? Yes\nAre there example codes/notebooks/toolkits available showing how the data can be used? Yes\nWhat is the license for the data?\n\nThese data may be redistributed and used without restriction\nIs the license standardized and machine-readable (e.g. Creative Commons)? Yes\n\nHas this dataset already been used in AI or ML activities? No\nAre there recommendations on the intended use of the data, and uses that are not recommended? Yes [TODO: link to documentation]\n\n\n\n\n\n\n\nNote\n\n\n\n\nAsk NCEI for license information\nScience Team: White paper for recommendations on the intended use of the product as a disclaimer and link the document"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#data-access",
    "href": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#data-access",
    "title": "PolarWatch Data Management",
    "section": "Data Access",
    "text": "Data Access\n\nWhat is/are the major file formats? netcdf\n\nIs this format machine-readable? Yes\nIs the data available in at least one open, non-proprietary format? Yes\nAre there tools/services to support data format conversion? Yes\n\nIf so, provide the link to the tools/services\n\n\nData delivery: ERDDAP\n\nDoes data access require authentication (e.g., a registered user account)? No\nCan the file be accessed via direct file downloading or ordering? Yes\nIs there an Application Programming Interface (API) or web service to access the data? Yes\nIf there is an API, does the API follow an open standard protocol (e.g., OGC)? Yes\nIf there is an API, is there documentation for the API? Yes\n\nIf “Yes”, please provide a URL to the documentation.\n\nIs the data available publicly via cloud services? Yes\n\nFor restricted data, have measures been taken to provide some access while still applying appropriate protection for privacy and security? Yes\n\nHas the data been aggregated to reduce granularity? Yes\nHas the data been anonymized / de-identified? Not applicable\nIs there secure access to the full dataset for authorized users? No"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#data-preparation",
    "href": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#data-preparation",
    "title": "PolarWatch Data Management",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nHave null values/gaps been filled? Yes\nHave outliers been identified? No\nIs the data gridded (regularly sampled in time and space)? Yes\n\nRegularly gridded in space and constant time-frequency\nIf the data is gridded, was it transformed from a different original sampling? Yes, from a different regular sampling\nIf the data is resampled from the original sampling, is the data also available at the original sampling? Yes\n\nAre there associated targets or labels for supervised learning techniques (i.e., can this be used as a training dataset for supervised learning techniques)? Yes\n\n\n\n\n\n\n\nNote\n\n\n\n\nCheck for the Pole hole"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#additional-metadata",
    "href": "datasets/ai_ready/nesdis_blendedsic_shem_daily.html#additional-metadata",
    "title": "PolarWatch Data Management",
    "section": "Additional Metadata",
    "text": "Additional Metadata\n\nPolarWatch Metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_shem_daily/index.html\n\n\n\n\n\n\n\nTO DO\n\n\n\n\nSTAR Team to create a white paper on intended use of blended SIC\nPolarWatch to check pole hole values in the dataset\nPolarWatch to create a Data Management Plan\nPolarWatch to contact NCEI for more info on license standards"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "PolarWatch Data Management",
    "section": "",
    "text": "PolarWatch Data List\n\nBlended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Arctic\n\nDMP — AI-Ready\n\nBlended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Antarctic\n\nDMP — AI-Ready"
  },
  {
    "objectID": "metadata.html",
    "href": "metadata.html",
    "title": "Metadata",
    "section": "",
    "text": "Metadata"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html",
    "href": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html",
    "title": "PolarWatch Data Management",
    "section": "",
    "text": "Link to Data Landing Page\n\nName : Blended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Arctic\nVersion : 1.0\nContact : Richard Dworak\nData Published : 12/18/2023\n\nIs this raw data or a derived/processed data product? Derived\nIs this observational data, simulation/model output, or synthetic data? Observational\nIs the data single-source or aggregated from several sources? Aggregated"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#general-information",
    "href": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#general-information",
    "title": "PolarWatch Data Management",
    "section": "",
    "text": "Link to Data Landing Page\n\nName : Blended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Arctic\nVersion : 1.0\nContact : Richard Dworak\nData Published : 12/18/2023\n\nIs this raw data or a derived/processed data product? Derived\nIs this observational data, simulation/model output, or synthetic data? Observational\nIs the data single-source or aggregated from several sources? Aggregated"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#data-quality",
    "href": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#data-quality",
    "title": "PolarWatch Data Management",
    "section": "Data Quality",
    "text": "Data Quality\n\nTimeliness:\n\nWill the dataset be updated? Yes, it will be updated. \n\nUpdated when new data are added daily\nWill there be different stages of the update? No\n\n\nData completeness\n\nIs there any documentation about the completeness of the dataset? Yes\n\nlink to documentation\n\nHow complete is the dataset compared to the expected spatial coverage? Complete\nHow complete is the dataset compared to the expected temporal coverage? Complete\n\nData consistency\n\nIs this dataset self-consistent in that its units, data types, and parameter names do not change over time and space? Yes\nIs this dataset’s units, data types, and parameter names consistent with similar data collections? Yes\nAre there processes to monitor for units, data types, and parameter consistency? No\n\nIf yes, what measures are taken? Manual review [TODO]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nCheck for pole hole, flag values?\nData consistency: create data management plan and add review process\n\n\n\n\nData bias\n\nIs there known bias in the dataset? No\n\nlink to documentation\n\nHave measures been taken to examine bias? No\nIs there reported bias in the data? No known bias\nIs there quantitative information about data resolution in space and time? Yes\nAre there published data quality procedures or reports? No\nIs the provenance of the dataset tracked and documented? No\nAre there checksums / other checks for data integrity? No\nWhat is the size of the dataset? Depending on the resource, this might be total data volume, dimensionality, number of images, data files, table rows, image size, etc. _ approximately 15 ~ 540 MB (file size per day)_"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#data-documentation",
    "href": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#data-documentation",
    "title": "PolarWatch Data Management",
    "section": "Data Documentation",
    "text": "Data Documentation\n\nDoes the dataset metadata follow a community/domain standard or convention? Yes\n\nIf the metadata follows a community/domain standard, which standard is it? CF-1.6, ACDD-1.3, NOAA CDR v1.0, GDS v2.0, COARDS\nIs the dataset metadata machine-readable? Yes\nDoes it include details on the spatial and temporal extent? Yes\n\nIs there a comprehensive data dictionary/codebook that describes what each element of the dataset means? parameters? Yes\n\nIs the data dictionary standardized? Yes\nIs the data dictionary machine-readable? Yes\nDo the parameters follow a defined standard? Yes\n\nIf the parameters follow a defined standard, which standard it is? CF-1.6\n\nAre parameters crosswalked in an ontology or common vocabulary (e.g. NIEM)? Not applicable\n\nDoes the dataset have a unique persistent identifier, e.g. DOI? Yes (CHECK DOI)\nIs there contact information for subject-matter experts? Yes\nIs there a mechanism for user feedback and suggestions? Yes\nAre there example codes/notebooks/toolkits available showing how the data can be used? Yes\nWhat is the license for the data?\n\nThese data may be redistributed and used without restriction\nIs the license standardized and machine-readable (e.g. Creative Commons)? Yes\n\nHas this dataset already been used in AI or ML activities? No\nAre there recommendations on the intended use of the data, and uses that are not recommended? Yes [TODO: link to documentation]\n\n\n\n\n\n\n\nNote\n\n\n\n\nAsk NCEI for license information\nScience Team: White paper for recommendations on the intended use of the product as a disclaimer and link the document"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#data-access",
    "href": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#data-access",
    "title": "PolarWatch Data Management",
    "section": "Data Access",
    "text": "Data Access\n\nWhat is/are the major file formats? netcdf\n\nIs this format machine-readable? Yes\nIs the data available in at least one open, non-proprietary format? Yes\nAre there tools/services to support data format conversion? Yes\n\nIf so, provide the link to the tools/services\n\n\nData delivery: ERDDAP\n\nDoes data access require authentication (e.g., a registered user account)? No\nCan the file be accessed via direct file downloading or ordering? Yes\nIs there an Application Programming Interface (API) or web service to access the data? Yes\nIf there is an API, does the API follow an open standard protocol (e.g., OGC)? Yes\nIf there is an API, is there documentation for the API? Yes\n\nIf “Yes”, please provide a URL to the documentation.\n\nIs the data available publicly via cloud services? Yes\n\nFor restricted data, have measures been taken to provide some access while still applying appropriate protection for privacy and security? Yes\n\nHas the data been aggregated to reduce granularity? Yes\nHas the data been anonymized / de-identified? Not applicable\nIs there secure access to the full dataset for authorized users? No"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#data-preparation",
    "href": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#data-preparation",
    "title": "PolarWatch Data Management",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nHave null values/gaps been filled? Yes\nHave outliers been identified? No\nIs the data gridded (regularly sampled in time and space)? Yes\n\nRegularly gridded in space and constant time-frequency\nIf the data is gridded, was it transformed from a different original sampling? Yes, from a different regular sampling\nIf the data is resampled from the original sampling, is the data also available at the original sampling? Yes\n\nAre there associated targets or labels for supervised learning techniques (i.e., can this be used as a training dataset for supervised learning techniques)? Yes\n\n\n\n\n\n\n\nNote\n\n\n\n\nCheck for the Pole hole"
  },
  {
    "objectID": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#additional-metadata",
    "href": "datasets/ai_ready/nesdis_blendedsic_nhem_daily.html#additional-metadata",
    "title": "PolarWatch Data Management",
    "section": "Additional Metadata",
    "text": "Additional Metadata\n\nPolarWatch Metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_nhem_daily/index.html\n\n\n\n\n\n\n\nTO DO\n\n\n\n\nSTAR Team to create a white paper on intended use of blended SIC\nPolarWatch to check pole hole values in the dataset\nPolarWatch to create a Data Management Plan\nPolarWatch to contact NCEI for more info on license standards"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PolarWatch Data Management",
    "section": "",
    "text": "Note\n\n\n\nThis document is a working copy.\n\n\nThis repository serves as a resource for the data management practices of PolarWatch. It includes documents and plans dedicated to the management of data throughout its lifecycle. ### Data Management Plan (DMP) A Data Management Plan (DMP) is a living document that details the data lifecycle, encompassing data creation, processing, access, ownership, and management strategies and tools.\nThe objective of PolarWatch is to disseminate remote sensing data, ensuring they are readily available. Consequently, the PolarWatch DMP focuses on aspects of the data lifecycle pertinent to its operations, such as data ingestion, processing, quality control, and management.\n\n\n\n\n\nflowchart LR\n  A(Get Data from Source) --&gt;B(Process, Q/C Data)\n  A --&gt; D(Create Metadata)\n  B --&gt; C(Store Data)\n  C --&gt; G(Backup Data)\n  B --&gt; D(Create Metadata)\n  C --&gt; F(Make Data Accessible)\n  D --&gt; F\n\n\n\n\n\n\nDiagram: General PolarWatch data workflow\nThe DMP Page provides an overview of the DMP components along with their detailed descriptions.\n\nAI-Ready Checklist\nThis checklist is developed through a collaboration of ESIP Data Readiness Cluster members include representatives from NOAA, NASA, USGS, and other organizations. The checklist will be updated periodically to reflect community feedback. The checklist aims to provide comprehensive metadata to support AI-ready research.\nsource: https://github.com/ESIPFed/data-readiness/blob/main/checklist-published/ai-ready-data-checklist-v.1.0.md\n\n\nData List\nThe Data List page presents a catalog of PolarWatch data products, including links to their respective DMP and AI-Ready documentation."
  },
  {
    "objectID": "dmp_template.html",
    "href": "dmp_template.html",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Source: https://guides.library.oregonstate.edu/dmp/general#s-lg-box-7689540\nGeneral DMP template based on general NSF guidelines\n\n\nGive a short description of the data and materials collected and created, and amounts (if known).\n\nDescription of data to be produced (experimental, observational, raw or derived, physical collections, models, images, etc.)\nHow data will be acquired (When? Where? Methods?)\nHow data will be processed (software used, algorithms, workflows, protocols)\nFile types and formats (CSV, tab-delimited, proprietary formats, naming conventions)\nHow much data will be generated? (range is OK)\nExisting data: if existing data are used, what are their origins? Will your data be combined with existing data? What is the relationship between your and existing data?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data types and formats in the Research Data Services website.\n\n\n\n\n\nMetadata includes all of the contextual information that would be necessary for someone to understand, use or recreate your dataset (even many years from now). It may include methodological information, definition of variables, units, assumptions made, etc… Metadata can take many forms, from readme files manually created, to automatically generated metadata by sensors, to metadata recorded in a metadata standard. Recording part of the metadata in normalized schemas and metadata standards will enhance discoverability and make your metadata computer friendly.\n\nWhat metadata are needed\nAny details that make data understandable and useable\nHow metadata will be created and/or captured\nLab notebooks? GPS units? Auto-saved on instrument? Manually entered?\nWhat format will be used for metadata?\nStandards for community (EML, ISO 19115, Dublin Core, etc… .\nJustification for format chosen\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data documentation and metadata in the Research Data Services website. When possible use data standards and/or metadata standards. A list of research metadata standards compiled by the Research Data Alliance can be found here. If you chose not to use a metadata standard, consider structuring metadata in the research project with your own template.\n\n\n\n\n\n\nDescribe how the data will be stored.\nDescribe how the data will be backed up.\n\nWhich locations\nAutomatic or manual\nWho will be responsible\nHow will the data be recovered in the event of an accident\n\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about storage and backups in the Research Data Services website. Oregon State University offers several cloud storage options. Data storage options for diferent clasifications of data at Oregon State University can be found at the OSU Data Management, Classification and Incident Response Policy.\n\n\n\n\n\nThis section is very important. Your funding agency needs to see that you have thought carefully about how you will prepare (manage) your data for sharing and how you will share your data with the public in reasonable time after the conclusion of your project. If the data are of a sensitive nature - human subject concerns, potential patentability, species/ecological endangerment concerns – such that public access is inappropriate, address here the means by which granular control and access will be achieved (e.g. formal consent agreements; anonymization of data; restricted access, only available within a secure network).\n\n\n\n\n\n\nTip\n\n\n\nInformation about Intellectual Property and datasets in the Research Data Services website. OSU Data Management, Classification and Incident Response Policy defines three data categories: unrestricted, sensitive and confidential. The policy outlines baselines of care. Data Management Plans are written before IRB approval, so you may not know all the details about how your sensitive data will need to be managed. Having plans for data sharing before getting IRB approval may help you to write your consent forms taking your data sharing goals into consideration.\n\n\n\nHow will potential users find out about your data?\nWhen will you make the data available?\nHow will you make the data available? (include resources needed to make the data available: equipment, systems, expertise, etc.)\nWhat is the process for gaining access to the data? (by request, open-access repository, etc.)\nWill access be chargeable?\nWill you be using persistent identifiers (e.g. DOI) for your datasets?\nWill a data sharing agreement or similar be required to share the dataset?\nExplain how the policies & procedures you outlined above relate to the reuse and redistribution of your data. Identify who will be allowed to use your data, how they will be allowed to use it, and if they will be allowed to disseminate your data.\nWill any permission restrictions need to be placed on the data? If you will restrict access to certain users explain why. Are you going to attach any licenses to the dataset?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data sharing in the Research Data Services website. You are welcome to share your research data in OSU’s institutional repository, ScholarsArchive@OSU. ScholarsArchive@OSU is a digital repository that promises preservation, discoverability, and persistency of digital objects and is supported by the OSU Libraries & Press. All datasets deposited to ScholarsArchive@OSU will be assigned DOIs, and metadata for discoverability, usability, and administrative needs of the data. A list of repositories can be found in re3data.org. Make sure that you evaluate the reliability of a repository first, if you choose it from this website without knowing much about it.\n\n\n\n\n\nThis section should cover your long-term strategy for preserving the data produced during your project. See section on data archiving.\n\nWhat data will be preserved for the long-term?\nWhat is the long-term strategy for maintaining, curating and archiving the data?\nWhere will it be preserved?\nWhich archive/repository/database have you identified as a place to deposit data?\nWhat procedures does your intended long-term data storage facility have in place for preservation and backup?\nHow long will/should data be kept beyond the life of the project?\nData transformations/formats needed\nWhat transformations will be necessary to prepare data for preservation / data sharing?\nWhat metadata/ documentation will be submitted alongside the data or created on deposit/ transformation in order to make the data reusable?\nWhat related information will be deposited?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data archival and preservation in the Research Data Services website. You are welcome to preserve your research data in OSU’s institutional repository, ScholarsArchive@OSU. ScholarsArchive@OSU is a digital repository that promises preservation, discoverability, and persistency of digital objects and is supported by the OSU Libraries & Press. All datasets deposited to ScholarsArchive@OSU will be assigned DOIs, and metadata for discoverability, usability, and administrative needs of the data.\nSometimes the sharing and preservation section of a Data Management Plan overlap if you are using a repository as both a sharing and a preservation strategy.\n\n\n\n\n\n\nWho will be responsible for making sure that the Data Management Plan will be implemented?\nWho will perform each of the data management tasks (data collection, data assurance and quality control, data documentation, data archiving, etc.).\nWhat are the procedures in place that ensure that if one member of the team leaves the project data management tasks will still be performed?"
  },
  {
    "objectID": "dmp_template.html#data-description",
    "href": "dmp_template.html#data-description",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Give a short description of the data and materials collected and created, and amounts (if known).\n\nDescription of data to be produced (experimental, observational, raw or derived, physical collections, models, images, etc.)\nHow data will be acquired (When? Where? Methods?)\nHow data will be processed (software used, algorithms, workflows, protocols)\nFile types and formats (CSV, tab-delimited, proprietary formats, naming conventions)\nHow much data will be generated? (range is OK)\nExisting data: if existing data are used, what are their origins? Will your data be combined with existing data? What is the relationship between your and existing data?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data types and formats in the Research Data Services website."
  },
  {
    "objectID": "dmp_template.html#metadata",
    "href": "dmp_template.html#metadata",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Metadata includes all of the contextual information that would be necessary for someone to understand, use or recreate your dataset (even many years from now). It may include methodological information, definition of variables, units, assumptions made, etc… Metadata can take many forms, from readme files manually created, to automatically generated metadata by sensors, to metadata recorded in a metadata standard. Recording part of the metadata in normalized schemas and metadata standards will enhance discoverability and make your metadata computer friendly.\n\nWhat metadata are needed\nAny details that make data understandable and useable\nHow metadata will be created and/or captured\nLab notebooks? GPS units? Auto-saved on instrument? Manually entered?\nWhat format will be used for metadata?\nStandards for community (EML, ISO 19115, Dublin Core, etc… .\nJustification for format chosen\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data documentation and metadata in the Research Data Services website. When possible use data standards and/or metadata standards. A list of research metadata standards compiled by the Research Data Alliance can be found here. If you chose not to use a metadata standard, consider structuring metadata in the research project with your own template."
  },
  {
    "objectID": "dmp_template.html#storage-and-backup",
    "href": "dmp_template.html#storage-and-backup",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Describe how the data will be stored.\nDescribe how the data will be backed up.\n\nWhich locations\nAutomatic or manual\nWho will be responsible\nHow will the data be recovered in the event of an accident\n\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about storage and backups in the Research Data Services website. Oregon State University offers several cloud storage options. Data storage options for diferent clasifications of data at Oregon State University can be found at the OSU Data Management, Classification and Incident Response Policy."
  },
  {
    "objectID": "dmp_template.html#policies-for-access-and-sharing",
    "href": "dmp_template.html#policies-for-access-and-sharing",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "This section is very important. Your funding agency needs to see that you have thought carefully about how you will prepare (manage) your data for sharing and how you will share your data with the public in reasonable time after the conclusion of your project. If the data are of a sensitive nature - human subject concerns, potential patentability, species/ecological endangerment concerns – such that public access is inappropriate, address here the means by which granular control and access will be achieved (e.g. formal consent agreements; anonymization of data; restricted access, only available within a secure network).\n\n\n\n\n\n\nTip\n\n\n\nInformation about Intellectual Property and datasets in the Research Data Services website. OSU Data Management, Classification and Incident Response Policy defines three data categories: unrestricted, sensitive and confidential. The policy outlines baselines of care. Data Management Plans are written before IRB approval, so you may not know all the details about how your sensitive data will need to be managed. Having plans for data sharing before getting IRB approval may help you to write your consent forms taking your data sharing goals into consideration.\n\n\n\nHow will potential users find out about your data?\nWhen will you make the data available?\nHow will you make the data available? (include resources needed to make the data available: equipment, systems, expertise, etc.)\nWhat is the process for gaining access to the data? (by request, open-access repository, etc.)\nWill access be chargeable?\nWill you be using persistent identifiers (e.g. DOI) for your datasets?\nWill a data sharing agreement or similar be required to share the dataset?\nExplain how the policies & procedures you outlined above relate to the reuse and redistribution of your data. Identify who will be allowed to use your data, how they will be allowed to use it, and if they will be allowed to disseminate your data.\nWill any permission restrictions need to be placed on the data? If you will restrict access to certain users explain why. Are you going to attach any licenses to the dataset?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data sharing in the Research Data Services website. You are welcome to share your research data in OSU’s institutional repository, ScholarsArchive@OSU. ScholarsArchive@OSU is a digital repository that promises preservation, discoverability, and persistency of digital objects and is supported by the OSU Libraries & Press. All datasets deposited to ScholarsArchive@OSU will be assigned DOIs, and metadata for discoverability, usability, and administrative needs of the data. A list of repositories can be found in re3data.org. Make sure that you evaluate the reliability of a repository first, if you choose it from this website without knowing much about it."
  },
  {
    "objectID": "dmp_template.html#plans-for-archiving-data-samples-and-other-research-products-and-for-preservation-of-access-to-them",
    "href": "dmp_template.html#plans-for-archiving-data-samples-and-other-research-products-and-for-preservation-of-access-to-them",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "This section should cover your long-term strategy for preserving the data produced during your project. See section on data archiving.\n\nWhat data will be preserved for the long-term?\nWhat is the long-term strategy for maintaining, curating and archiving the data?\nWhere will it be preserved?\nWhich archive/repository/database have you identified as a place to deposit data?\nWhat procedures does your intended long-term data storage facility have in place for preservation and backup?\nHow long will/should data be kept beyond the life of the project?\nData transformations/formats needed\nWhat transformations will be necessary to prepare data for preservation / data sharing?\nWhat metadata/ documentation will be submitted alongside the data or created on deposit/ transformation in order to make the data reusable?\nWhat related information will be deposited?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data archival and preservation in the Research Data Services website. You are welcome to preserve your research data in OSU’s institutional repository, ScholarsArchive@OSU. ScholarsArchive@OSU is a digital repository that promises preservation, discoverability, and persistency of digital objects and is supported by the OSU Libraries & Press. All datasets deposited to ScholarsArchive@OSU will be assigned DOIs, and metadata for discoverability, usability, and administrative needs of the data.\nSometimes the sharing and preservation section of a Data Management Plan overlap if you are using a repository as both a sharing and a preservation strategy."
  },
  {
    "objectID": "dmp_template.html#roles-and-responsibilities",
    "href": "dmp_template.html#roles-and-responsibilities",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Who will be responsible for making sure that the Data Management Plan will be implemented?\nWho will perform each of the data management tasks (data collection, data assurance and quality control, data documentation, data archiving, etc.).\nWhat are the procedures in place that ensure that if one member of the team leaves the project data management tasks will still be performed?"
  }
]