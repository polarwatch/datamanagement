[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PolarWatch Metadata Information Page",
    "section": "",
    "text": "The PolarWatch Metadata Information Page is designed to provide comprehensive metadata-related information on the data products distributed by PolarWatch, emphasizing adherence to FAIRS and Open Data principles.\nFurthermore, it aims to facilitate both current and future data product distributions through the PolarWatch data server by offering detailed metadata guidelines and recommendations.\n\nFor Data Users\nOn the Data List page, users can access a variety of resources, including:\n\nData Change Logs: Provides updates on any modifications to data products, such as variable adjustments or corrections to missing dates.\nAI-Ready Checklist: Delivers metadata specifications for AI-ready open environmental data, ensuring readiness for artificial intelligence applications.\nData/Server Availability: Supplies notifications regarding the availability of data or server access, keeping users informed of operational status.\n\n\n\nFor Data Developers\nGuidelines and recommendations can be found on the Guidelines page:\n\nData Processing Workflow: an overview of the methods PolarWatch employs to process and distribute data.\nPolarWatch Metadata Recommendations: These guidelines are designed for data products hosted on the PolarWatch ERDDAP Server, outlining metadata attributes and descriptions in accordance with established industry convention standards, as noted in the Standard column.\nAI-Ready Checklist Guidelines: Presents a set of guidelines and recommendations for crafting metadata that meets the criteria for AI-ready open environmental data. This document mirrors the latest version available from the source repository, ensuring users have access to the most current standards."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "PolarWatch Data Management",
    "section": "",
    "text": "PolarWatch Data List\nwith PolarWatch unique dataset IDs\n\nBlended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Arctic (nesdis_blendedsic_nhem_daily)\n\nWorkflow — AI-Ready — Log\n\nBlended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Antarctic (nesdis_blendedsic_shem_daily)\n\nWorkflow — AI-Ready — Log\n\nLatitudes and Longitudes for EASE-2 projected data at 1km, Arctic and Antarctic (nesdis_ease2_latlon_nhem_1k, nesdis_ease2_latlon_shem_1k)\n\nWorkflow — Log"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/dmp.html",
    "href": "datasets/nesdis_blendedsic_shem_daily/dmp.html",
    "title": "Data Management: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "Updated Apr 3, 2024\n\n\n\nThis dataset represents the 1km Blended sea ice concentration for the Arctic, utilizing data from the AMSR2 instrument aboard the GCOM-W1 satellite and VIIRS instrument on NOAA-21. The daily sea ice concentration values are stored in the 1 km EASE2-Grid format.\nThese data products are developed through a collaboration between NESDIS and the University of Wisconsin. For more information on the algorithm development, you can visit the provided link: Algorithm Development.\nThe data file, available in NetCDF format, is generated daily with a 2-day delay for data availability. For instance, the data file for February 10, 2024, becomes accessible on February 12, 2024. File sizes vary approximately between 15MB and 360MB, and specific file sizes can be checked on the ERDDAP file page.\nDistribution of the data files is managed through PolarWatch ERDDAP, where they can also be previewed in the PolarWatch Catalog.\n\n\n\n\n\n\ndisclaimer\n\n\n\nPolarWatch ERDDAP enables data subsetting and downloading in various formats through the Data Download Form. However, please note that this dataset is provided in EASE-2 (EPSG:6932) coordinates. For optimal results, direct file downloads from ERDDAP File page are strongly recommended.\n\n\n\n\n\nDaily processing is automated and scheduled to run daily to check, download, compress and store and backup newly created netcdf file from the FTP server.\n\n\n\n\n\nflowchart LR\n  A(File on FTP Server) --&gt;B(File Download to PolarWatch)\n  B --&gt; C(Compressed, Stored, Backed up)\n  C --&gt; D(Accessible on ERDDAP, Catalog)\n\n\n\n\n\n\n\nPolarWatch checks and downloads daily netcdf file from NESDIS/Univ of Wisconin daily (scheduled cron job)\nPolarWatch compresses netcdf file and store on a data server to be accessible\nPolarWatch backsup data file\n\n\n\n\nPolarWatch provides extensive metadata on ERDDAP in addition to embedded metadata in NetCDF. The metadata standard used is CF-16, and both ERDDAP metadata and NetCDF metadata are machine readable.\nThe metadata was created by the data product developer with the template/guidelines provided by PolarWatch. link to template\nERDDAP metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_nhem_daily/index.html\n\n\n\n\n\n\nProjection attributes\n\n\n\nFor software readable projection information is stored in the following attributes srid, proj4text, grid_mapping , grid_mapping_epsg_code: 6932.\n\n\n\n\n\nData are stored in directory on the PolarWatch data server and ERDDAP points to the directory. Data are automatically backed up on a PolarWatch backup server. In the case of the event of an accident, the recovery will be handled by PolarWatch team.\n\n\n\nData are publically accessible. Please use NCEI Data Licensing . ERDDAP is the primary data distribution system with a web interface.\nData can be searched and accessed:\n\nPolarWatch Catalog or PolarWatch ERDDAP Web Interface\nERDDAP RESTful web services for software to access data.\nTutorials and code samples are available to access data and metadata in commonly used languages (i.e. R, Python)\nContact PolarWatch Operatins Manager at polar.watch@noaa.gov\n\n\n\n\nPolarWatch collaborates with data developers to manage and distribute both actively updated datasets and those that have become deprecated. While ensuring continued access to these varied datasets, it’s important to note that PolarWatch does not serve as an archive for data.\n\n\n\n\nThe PolarWatch Operations Manager is tasked with the implementation, documentation, and periodic updating of the Data Management Plan.\nThe data workflow is designed to be automated. This process is closely monitored, with automatic notifications being sent out in the event of any errors.\nThe documentation for internal data processing is accessible internally, ensuring that relevant team members can access it as needed. Additionally, all scripts associated with this processing are stored in a private repository."
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/dmp.html#data-description",
    "href": "datasets/nesdis_blendedsic_shem_daily/dmp.html#data-description",
    "title": "Data Management: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "This dataset represents the 1km Blended sea ice concentration for the Arctic, utilizing data from the AMSR2 instrument aboard the GCOM-W1 satellite and VIIRS instrument on NOAA-21. The daily sea ice concentration values are stored in the 1 km EASE2-Grid format.\nThese data products are developed through a collaboration between NESDIS and the University of Wisconsin. For more information on the algorithm development, you can visit the provided link: Algorithm Development.\nThe data file, available in NetCDF format, is generated daily with a 2-day delay for data availability. For instance, the data file for February 10, 2024, becomes accessible on February 12, 2024. File sizes vary approximately between 15MB and 360MB, and specific file sizes can be checked on the ERDDAP file page.\nDistribution of the data files is managed through PolarWatch ERDDAP, where they can also be previewed in the PolarWatch Catalog.\n\n\n\n\n\n\ndisclaimer\n\n\n\nPolarWatch ERDDAP enables data subsetting and downloading in various formats through the Data Download Form. However, please note that this dataset is provided in EASE-2 (EPSG:6932) coordinates. For optimal results, direct file downloads from ERDDAP File page are strongly recommended."
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/dmp.html#process-description",
    "href": "datasets/nesdis_blendedsic_shem_daily/dmp.html#process-description",
    "title": "Data Management: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "Daily processing is automated and scheduled to run daily to check, download, compress and store and backup newly created netcdf file from the FTP server.\n\n\n\n\n\nflowchart LR\n  A(File on FTP Server) --&gt;B(File Download to PolarWatch)\n  B --&gt; C(Compressed, Stored, Backed up)\n  C --&gt; D(Accessible on ERDDAP, Catalog)\n\n\n\n\n\n\n\nPolarWatch checks and downloads daily netcdf file from NESDIS/Univ of Wisconin daily (scheduled cron job)\nPolarWatch compresses netcdf file and store on a data server to be accessible\nPolarWatch backsup data file"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/dmp.html#metadata",
    "href": "datasets/nesdis_blendedsic_shem_daily/dmp.html#metadata",
    "title": "Data Management: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "PolarWatch provides extensive metadata on ERDDAP in addition to embedded metadata in NetCDF. The metadata standard used is CF-16, and both ERDDAP metadata and NetCDF metadata are machine readable.\nThe metadata was created by the data product developer with the template/guidelines provided by PolarWatch. link to template\nERDDAP metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_nhem_daily/index.html\n\n\n\n\n\n\nProjection attributes\n\n\n\nFor software readable projection information is stored in the following attributes srid, proj4text, grid_mapping , grid_mapping_epsg_code: 6932."
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/dmp.html#storage-and-backup",
    "href": "datasets/nesdis_blendedsic_shem_daily/dmp.html#storage-and-backup",
    "title": "Data Management: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "Data are stored in directory on the PolarWatch data server and ERDDAP points to the directory. Data are automatically backed up on a PolarWatch backup server. In the case of the event of an accident, the recovery will be handled by PolarWatch team."
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/dmp.html#policies-for-access-and-sharing",
    "href": "datasets/nesdis_blendedsic_shem_daily/dmp.html#policies-for-access-and-sharing",
    "title": "Data Management: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "Data are publically accessible. Please use NCEI Data Licensing . ERDDAP is the primary data distribution system with a web interface.\nData can be searched and accessed:\n\nPolarWatch Catalog or PolarWatch ERDDAP Web Interface\nERDDAP RESTful web services for software to access data.\nTutorials and code samples are available to access data and metadata in commonly used languages (i.e. R, Python)\nContact PolarWatch Operatins Manager at polar.watch@noaa.gov"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/dmp.html#plans-for-archiving-data",
    "href": "datasets/nesdis_blendedsic_shem_daily/dmp.html#plans-for-archiving-data",
    "title": "Data Management: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "PolarWatch collaborates with data developers to manage and distribute both actively updated datasets and those that have become deprecated. While ensuring continued access to these varied datasets, it’s important to note that PolarWatch does not serve as an archive for data."
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/dmp.html#roles-and-responsibilities",
    "href": "datasets/nesdis_blendedsic_shem_daily/dmp.html#roles-and-responsibilities",
    "title": "Data Management: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "The PolarWatch Operations Manager is tasked with the implementation, documentation, and periodic updating of the Data Management Plan.\nThe data workflow is designed to be automated. This process is closely monitored, with automatic notifications being sent out in the event of any errors.\nThe documentation for internal data processing is accessible internally, ensuring that relevant team members can access it as needed. Additionally, all scripts associated with this processing are stored in a private repository."
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/dmp.html",
    "href": "datasets/nesdis_blendedsic_nhem_daily/dmp.html",
    "title": "Data Management: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "Updated Apr 3, 2024\n\n\n\nThis dataset represents the 1km Blended sea ice concentration for the Arctic, utilizing data from the AMSR2 instrument aboard the GCOM-W1 satellite and VIIRS instrument on NOAA-21. The daily sea ice concentration values are stored in the 1 km EASE2-Grid format.\nThese data products are developed through a collaboration between NESDIS and the University of Wisconsin. For more information on the algorithm development, you can visit the provided link: Algorithm Development.\nThe data file, available in NetCDF format, is generated daily with a 2-day delay for data availability. For instance, the data file for February 10, 2024, becomes accessible on February 12, 2024. File sizes vary approximately between 15MB and 360MB, and specific file sizes can be checked on the ERDDAP file page.\nDistribution of the data files is managed through PolarWatch ERDDAP, where they can also be previewed in the PolarWatch Catalog.\n\n\n\n\n\n\ndisclaimer\n\n\n\nPolarWatch ERDDAP enables data subsetting and downloading in various formats through the Data Download Form. However, please note that this dataset is provided in EASE-2 (EPSG:6931) coordinates. For optimal results, direct file downloads from ERDDAP File page are strongly recommended.\n\n\n\n\n\nDaily processing is automated and scheduled to run daily to check, download, compress and store and backup newly created netcdf file from the FTP server.\n\n\n\n\n\nflowchart LR\n  A(File on FTP Server) --&gt;B(File Download to PolarWatch)\n  B --&gt; C(Compressed, Stored, Backed up)\n  C --&gt; D(Accessible on ERDDAP, Catalog)\n\n\n\n\n\n\n\nPolarWatch checks and downloads daily netcdf file from NESDIS/Univ of Wisconin daily (scheduled cron job)\nPolarWatch compresses netcdf file and store on a data server to be accessible\nPolarWatch backsup data file\n\n\n\n\nPolarWatch provides extensive metadata on ERDDAP in addition to embedded metadata in NetCDF. The metadata standard used is CF-16, and both ERDDAP metadata and NetCDF metadata are machine readable.\nThe metadata was created by the data product developer with the template/guidelines provided by PolarWatch. link to template\nERDDAP metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_nhem_daily/index.html\n\n\n\n\n\n\nProjection attributes\n\n\n\nFor software readable projection information is stored in the following attributes srid, proj4text, grid_mapping , grid_mapping_epsg_code: 6931.\n\n\n\n\n\nData are stored in directory on the PolarWatch data server and ERDDAP points to the directory. Data are automatically backed up on a PolarWatch backup server. In the case of the event of an accident, the recovery will be handled by PolarWatch team.\n\n\n\nData are publically accessible. Please use NCEI Data Licensing . ERDDAP is the primary data distribution system with a web interface.\nData can be searched and accessed:\n\nPolarWatch Catalog or PolarWatch ERDDAP Web Interface\nERDDAP RESTful web services for software to access data.\nTutorials and code samples are available to access data and metadata in commonly used languages (i.e. R, Python)\nContact PolarWatch Operatins Manager at polar.watch@noaa.gov\n\n\n\n\nPolarWatch collaborates with data developers to manage and distribute both actively updated datasets and those that have become deprecated. While ensuring continued access to these varied datasets, it’s important to note that PolarWatch does not serve as an archive for data.\n\n\n\n\nThe PolarWatch Operations Manager is tasked with the implementation, documentation, and periodic updating of the Data Management Plan.\nThe data workflow is designed to be automated. This process is closely monitored, with automatic notifications being sent out in the event of any errors.\nThe documentation for internal data processing is accessible internally, ensuring that relevant team members can access it as needed. Additionally, all scripts associated with this processing are stored in a private repository."
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#data-description",
    "href": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#data-description",
    "title": "Data Management: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "This dataset represents the 1km Blended sea ice concentration for the Arctic, utilizing data from the AMSR2 instrument aboard the GCOM-W1 satellite and VIIRS instrument on NOAA-21. The daily sea ice concentration values are stored in the 1 km EASE2-Grid format.\nThese data products are developed through a collaboration between NESDIS and the University of Wisconsin. For more information on the algorithm development, you can visit the provided link: Algorithm Development.\nThe data file, available in NetCDF format, is generated daily with a 2-day delay for data availability. For instance, the data file for February 10, 2024, becomes accessible on February 12, 2024. File sizes vary approximately between 15MB and 360MB, and specific file sizes can be checked on the ERDDAP file page.\nDistribution of the data files is managed through PolarWatch ERDDAP, where they can also be previewed in the PolarWatch Catalog.\n\n\n\n\n\n\ndisclaimer\n\n\n\nPolarWatch ERDDAP enables data subsetting and downloading in various formats through the Data Download Form. However, please note that this dataset is provided in EASE-2 (EPSG:6931) coordinates. For optimal results, direct file downloads from ERDDAP File page are strongly recommended."
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#process-description",
    "href": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#process-description",
    "title": "Data Management: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "Daily processing is automated and scheduled to run daily to check, download, compress and store and backup newly created netcdf file from the FTP server.\n\n\n\n\n\nflowchart LR\n  A(File on FTP Server) --&gt;B(File Download to PolarWatch)\n  B --&gt; C(Compressed, Stored, Backed up)\n  C --&gt; D(Accessible on ERDDAP, Catalog)\n\n\n\n\n\n\n\nPolarWatch checks and downloads daily netcdf file from NESDIS/Univ of Wisconin daily (scheduled cron job)\nPolarWatch compresses netcdf file and store on a data server to be accessible\nPolarWatch backsup data file"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#metadata",
    "href": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#metadata",
    "title": "Data Management: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "PolarWatch provides extensive metadata on ERDDAP in addition to embedded metadata in NetCDF. The metadata standard used is CF-16, and both ERDDAP metadata and NetCDF metadata are machine readable.\nThe metadata was created by the data product developer with the template/guidelines provided by PolarWatch. link to template\nERDDAP metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_nhem_daily/index.html\n\n\n\n\n\n\nProjection attributes\n\n\n\nFor software readable projection information is stored in the following attributes srid, proj4text, grid_mapping , grid_mapping_epsg_code: 6931."
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#storage-and-backup",
    "href": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#storage-and-backup",
    "title": "Data Management: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "Data are stored in directory on the PolarWatch data server and ERDDAP points to the directory. Data are automatically backed up on a PolarWatch backup server. In the case of the event of an accident, the recovery will be handled by PolarWatch team."
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#policies-for-access-and-sharing",
    "href": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#policies-for-access-and-sharing",
    "title": "Data Management: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "Data are publically accessible. Please use NCEI Data Licensing . ERDDAP is the primary data distribution system with a web interface.\nData can be searched and accessed:\n\nPolarWatch Catalog or PolarWatch ERDDAP Web Interface\nERDDAP RESTful web services for software to access data.\nTutorials and code samples are available to access data and metadata in commonly used languages (i.e. R, Python)\nContact PolarWatch Operatins Manager at polar.watch@noaa.gov"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#plans-for-archiving-data",
    "href": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#plans-for-archiving-data",
    "title": "Data Management: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "PolarWatch collaborates with data developers to manage and distribute both actively updated datasets and those that have become deprecated. While ensuring continued access to these varied datasets, it’s important to note that PolarWatch does not serve as an archive for data."
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#roles-and-responsibilities",
    "href": "datasets/nesdis_blendedsic_nhem_daily/dmp.html#roles-and-responsibilities",
    "title": "Data Management: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "The PolarWatch Operations Manager is tasked with the implementation, documentation, and periodic updating of the Data Management Plan.\nThe data workflow is designed to be automated. This process is closely monitored, with automatic notifications being sent out in the event of any errors.\nThe documentation for internal data processing is accessible internally, ensuring that relevant team members can access it as needed. Additionally, all scripts associated with this processing are stored in a private repository."
  },
  {
    "objectID": "datasets/nesdis_ease2_latlon_1k/dmp.html",
    "href": "datasets/nesdis_ease2_latlon_1k/dmp.html",
    "title": "Data Management:  nesdis_blendednesdis_ease2_latlon_nhem_1k, nesdis_ease2_latlon_shem_1k",
    "section": "",
    "text": "Updated Apr 18, 2024\n\n\n\nThis dataset includes latitude and longitude grids that correspond to the Y-grid and X-grid used in the NESDIS sea ice products in the Arctic and Antarctic.\nPresented in the EASE-2 (Equal-Area Scalable Earth-2) projection at a 1km resolution, this dataset serves as ancillary data to the sea ice data products (nesdis_blendedsic_nhem_daily, nesdis_blendedsic_shem_daily) in the same projection:\n\n\n\n\n\n\n\nAncillary data identifier\nRemote sensing data identifier\n\n\n\n\nnesdis_blendednesdis_ease2_latlon_nhem_1k\nnesdis_blendedsic_nhem_daily\n\n\nnesdis_blendednesdis_ease2_latlon_shem_1k\nnesdis_blendedsic_shem_daily\n\n\n\n* data identifiers are unique data ids used on the PolarWatch ERDDAP data server\nThe file sizes for the Arctic and Antarctic data files are approximately 490MB and 395MB, respectively. These files can be downloaded from the PolarWatch ERDDAP server.\n\nArctic file download : https://polarwatch.noaa.gov/erddap/files/nesdis_ease2_latlon_nhem_1k/\nAntarctic file download : https://polarwatch.noaa.gov/erddap/files/nesdis_ease2_latlon_shem_1k/\n\n\n\n\nThe data files were developed by NESDIS in collaboration with the University of Wisconsin and provided to PolarWatch. Additional projection metadata attributes were added to the files, and they were compressed for efficient distribution.\n\n\n\n\n\nflowchart LR\n  A(File on FTP Server) --&gt;B(File Download to PolarWatch)\n  B --&gt; C(Metadata added to files, Compressed, Stored)\n  C --&gt; D(Accessible on ERDDAP)\n\n\n\n\n\n\n\n\n\nPolarWatch provides extensive metadata on ERDDAP in addition to embedded metadata in NetCDF. PolarWatch added additional crs (coordinate reference system) attributes to be machine readable by widely used software. The additional attributes are srid, proj4text, spatial_ref.\nThe metadata standard used is CF-16, and both ERDDAP metadata and NetCDF metadata are machine readable.\nAdditional crs attributes added to files\n# for northern hemisphere file (arctic)\n    crs:srid = \"EPSG:6931\" ;\n    crs:proj4text = \"+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs\"\n    crs:spatial_ref = \"PROJCS[\\\"WGS 84 / NSIDC EASE-Grid 2.0 North\\\",GEOGCS[\\\"WGS 84\\\",\n      DATUM[\\\"WGS_1984\\\",SPHEROID[\\\"WGS 84\\\",6378137,298.257223563,AUTHORITY\n      [\\\"EPSG\\\",\\\"7030\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"6326\\\"]],PRIMEM[\\\"Greenwich\\\",\n      0,AUTHORITY[\\\"EPSG\\\",\\\"8901\\\"]],UNIT[\\\"degree\\\",0.0174532925199433,AUTHORITY\n      [\\\"EPSG\\\",\\\"9122\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"4326\\\"]],PROJECTION[\\\"Lambert_Azimuthal_Equal_Area\\\"],\n      PARAMETER[\\\"latitude_of_center\\\",90],PARAMETER[\\\"longitude_of_center\\\",0],\n      PARAMETER[\\\"false_easting\\\",0],PARAMETER[\\\"false_northing\\\",0],\n      UNIT[\\\"metre\\\",1,AUTHORITY[\\\"EPSG\\\",\\\"9001\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"6931\\\"]]\" ;\n\n\n# For southern hemisphere file (antarctic)\n    crs:srid = \"EPSG:6932\" ;\n    crs:proj4text = \"+proj=laea +lat_0=-90 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs\"\n    crs:spatial_ref = PROJCS[\\\"WGS 84 / NSIDC EASE-Grid 2.0 South\\\",\n    GEOGCS[\\\"WGS 84\\\",DATUM[\\\"WGS_1984\\\",SPHEROID[\\\"WGS 84\\\",6378137,298.257223563,\n    AUTHORITY[\\\"EPSG\\\",\\\"7030\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"6326\\\"]],\n    PRIMEM[\\\"Greenwich\\\",0,AUTHORITY[\\\"EPSG\\\",\\\"8901\\\"]],\n    UNIT[\\\"degree\\\",0.0174532925199433,AUTHORITY[\\\"EPSG\\\",\\\"9122\\\"]],\n    AUTHORITY[\\\"EPSG\\\",\\\"4326\\\"]],PROJECTION[\\\"Lambert_Azimuthal_Equal_Area\\\"],\n    PARAMETER[\\\"latitude_of_center\\\",-90],PARAMETER[\\\"longitude_of_center\\\",0],\n    PARAMETER[\\\"false_easting\\\",0],PARAMETER[\\\"false_northing\\\",0],\n    UNIT[\\\"metre\\\",1,AUTHORITY[\\\"EPSG\\\",\\\"9001\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"6932\\\"]]\n\nERDDAP metadata links\n\nArctic: https://polarwatch.noaa.gov/erddap/info/nesdis_ease2_latlon_nhem_1k/index.html\nAntarctic: https://polarwatch.noaa.gov/erddap/info/nesdis_ease2_latlon_shem_1k/index.html\n\n\n\n\nData are stored in directory on the PolarWatch data server and ERDDAP points to the directory. In the case of the event of an accident, the recovery will be handled by PolarWatch team.\n\n\n\nData are publically accessible. Please use NCEI Data Licensing . ERDDAP is the primary data distribution system with a web interface.\nData can be searched and accessed:\n\nPolarWatch Catalog or PolarWatch ERDDAP Web Interface\nERDDAP RESTful web services for software to access data.\nTutorials and code samples are available to access data and metadata in commonly used languages (i.e. R, Python)\nContact PolarWatch Operatins Manager at polar.watch@noaa.gov\n\n\n\n\nPolarWatch collaborates with data developers to manage and distribute both actively updated datasets and those that have become deprecated. While ensuring continued access to these varied datasets, it’s important to note that PolarWatch does not serve as an archive for data.\n\n\n\n\nThe PolarWatch Operations Manager is tasked with the implementation, documentation, and periodic updating of the Data Management Plan.\nThe data workflow is designed to be automated. This process is closely monitored, with automatic notifications being sent out in the event of any errors.\nThe documentation for internal data processing is accessible internally, ensuring that relevant team members can access it as needed. Additionally, all scripts associated with this processing are stored in a private repository."
  },
  {
    "objectID": "datasets/nesdis_ease2_latlon_1k/dmp.html#data-description",
    "href": "datasets/nesdis_ease2_latlon_1k/dmp.html#data-description",
    "title": "Data Management:  nesdis_blendednesdis_ease2_latlon_nhem_1k, nesdis_ease2_latlon_shem_1k",
    "section": "",
    "text": "This dataset includes latitude and longitude grids that correspond to the Y-grid and X-grid used in the NESDIS sea ice products in the Arctic and Antarctic.\nPresented in the EASE-2 (Equal-Area Scalable Earth-2) projection at a 1km resolution, this dataset serves as ancillary data to the sea ice data products (nesdis_blendedsic_nhem_daily, nesdis_blendedsic_shem_daily) in the same projection:\n\n\n\n\n\n\n\nAncillary data identifier\nRemote sensing data identifier\n\n\n\n\nnesdis_blendednesdis_ease2_latlon_nhem_1k\nnesdis_blendedsic_nhem_daily\n\n\nnesdis_blendednesdis_ease2_latlon_shem_1k\nnesdis_blendedsic_shem_daily\n\n\n\n* data identifiers are unique data ids used on the PolarWatch ERDDAP data server\nThe file sizes for the Arctic and Antarctic data files are approximately 490MB and 395MB, respectively. These files can be downloaded from the PolarWatch ERDDAP server.\n\nArctic file download : https://polarwatch.noaa.gov/erddap/files/nesdis_ease2_latlon_nhem_1k/\nAntarctic file download : https://polarwatch.noaa.gov/erddap/files/nesdis_ease2_latlon_shem_1k/"
  },
  {
    "objectID": "datasets/nesdis_ease2_latlon_1k/dmp.html#process-description",
    "href": "datasets/nesdis_ease2_latlon_1k/dmp.html#process-description",
    "title": "Data Management:  nesdis_blendednesdis_ease2_latlon_nhem_1k, nesdis_ease2_latlon_shem_1k",
    "section": "",
    "text": "The data files were developed by NESDIS in collaboration with the University of Wisconsin and provided to PolarWatch. Additional projection metadata attributes were added to the files, and they were compressed for efficient distribution.\n\n\n\n\n\nflowchart LR\n  A(File on FTP Server) --&gt;B(File Download to PolarWatch)\n  B --&gt; C(Metadata added to files, Compressed, Stored)\n  C --&gt; D(Accessible on ERDDAP)"
  },
  {
    "objectID": "datasets/nesdis_ease2_latlon_1k/dmp.html#metadata",
    "href": "datasets/nesdis_ease2_latlon_1k/dmp.html#metadata",
    "title": "Data Management:  nesdis_blendednesdis_ease2_latlon_nhem_1k, nesdis_ease2_latlon_shem_1k",
    "section": "",
    "text": "PolarWatch provides extensive metadata on ERDDAP in addition to embedded metadata in NetCDF. PolarWatch added additional crs (coordinate reference system) attributes to be machine readable by widely used software. The additional attributes are srid, proj4text, spatial_ref.\nThe metadata standard used is CF-16, and both ERDDAP metadata and NetCDF metadata are machine readable.\nAdditional crs attributes added to files\n# for northern hemisphere file (arctic)\n    crs:srid = \"EPSG:6931\" ;\n    crs:proj4text = \"+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs\"\n    crs:spatial_ref = \"PROJCS[\\\"WGS 84 / NSIDC EASE-Grid 2.0 North\\\",GEOGCS[\\\"WGS 84\\\",\n      DATUM[\\\"WGS_1984\\\",SPHEROID[\\\"WGS 84\\\",6378137,298.257223563,AUTHORITY\n      [\\\"EPSG\\\",\\\"7030\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"6326\\\"]],PRIMEM[\\\"Greenwich\\\",\n      0,AUTHORITY[\\\"EPSG\\\",\\\"8901\\\"]],UNIT[\\\"degree\\\",0.0174532925199433,AUTHORITY\n      [\\\"EPSG\\\",\\\"9122\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"4326\\\"]],PROJECTION[\\\"Lambert_Azimuthal_Equal_Area\\\"],\n      PARAMETER[\\\"latitude_of_center\\\",90],PARAMETER[\\\"longitude_of_center\\\",0],\n      PARAMETER[\\\"false_easting\\\",0],PARAMETER[\\\"false_northing\\\",0],\n      UNIT[\\\"metre\\\",1,AUTHORITY[\\\"EPSG\\\",\\\"9001\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"6931\\\"]]\" ;\n\n\n# For southern hemisphere file (antarctic)\n    crs:srid = \"EPSG:6932\" ;\n    crs:proj4text = \"+proj=laea +lat_0=-90 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs\"\n    crs:spatial_ref = PROJCS[\\\"WGS 84 / NSIDC EASE-Grid 2.0 South\\\",\n    GEOGCS[\\\"WGS 84\\\",DATUM[\\\"WGS_1984\\\",SPHEROID[\\\"WGS 84\\\",6378137,298.257223563,\n    AUTHORITY[\\\"EPSG\\\",\\\"7030\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"6326\\\"]],\n    PRIMEM[\\\"Greenwich\\\",0,AUTHORITY[\\\"EPSG\\\",\\\"8901\\\"]],\n    UNIT[\\\"degree\\\",0.0174532925199433,AUTHORITY[\\\"EPSG\\\",\\\"9122\\\"]],\n    AUTHORITY[\\\"EPSG\\\",\\\"4326\\\"]],PROJECTION[\\\"Lambert_Azimuthal_Equal_Area\\\"],\n    PARAMETER[\\\"latitude_of_center\\\",-90],PARAMETER[\\\"longitude_of_center\\\",0],\n    PARAMETER[\\\"false_easting\\\",0],PARAMETER[\\\"false_northing\\\",0],\n    UNIT[\\\"metre\\\",1,AUTHORITY[\\\"EPSG\\\",\\\"9001\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"6932\\\"]]\n\nERDDAP metadata links\n\nArctic: https://polarwatch.noaa.gov/erddap/info/nesdis_ease2_latlon_nhem_1k/index.html\nAntarctic: https://polarwatch.noaa.gov/erddap/info/nesdis_ease2_latlon_shem_1k/index.html"
  },
  {
    "objectID": "datasets/nesdis_ease2_latlon_1k/dmp.html#storage-and-backup",
    "href": "datasets/nesdis_ease2_latlon_1k/dmp.html#storage-and-backup",
    "title": "Data Management:  nesdis_blendednesdis_ease2_latlon_nhem_1k, nesdis_ease2_latlon_shem_1k",
    "section": "",
    "text": "Data are stored in directory on the PolarWatch data server and ERDDAP points to the directory. In the case of the event of an accident, the recovery will be handled by PolarWatch team."
  },
  {
    "objectID": "datasets/nesdis_ease2_latlon_1k/dmp.html#policies-for-access-and-sharing",
    "href": "datasets/nesdis_ease2_latlon_1k/dmp.html#policies-for-access-and-sharing",
    "title": "Data Management:  nesdis_blendednesdis_ease2_latlon_nhem_1k, nesdis_ease2_latlon_shem_1k",
    "section": "",
    "text": "Data are publically accessible. Please use NCEI Data Licensing . ERDDAP is the primary data distribution system with a web interface.\nData can be searched and accessed:\n\nPolarWatch Catalog or PolarWatch ERDDAP Web Interface\nERDDAP RESTful web services for software to access data.\nTutorials and code samples are available to access data and metadata in commonly used languages (i.e. R, Python)\nContact PolarWatch Operatins Manager at polar.watch@noaa.gov"
  },
  {
    "objectID": "datasets/nesdis_ease2_latlon_1k/dmp.html#plans-for-archiving-data",
    "href": "datasets/nesdis_ease2_latlon_1k/dmp.html#plans-for-archiving-data",
    "title": "Data Management:  nesdis_blendednesdis_ease2_latlon_nhem_1k, nesdis_ease2_latlon_shem_1k",
    "section": "",
    "text": "PolarWatch collaborates with data developers to manage and distribute both actively updated datasets and those that have become deprecated. While ensuring continued access to these varied datasets, it’s important to note that PolarWatch does not serve as an archive for data."
  },
  {
    "objectID": "datasets/nesdis_ease2_latlon_1k/dmp.html#roles-and-responsibilities",
    "href": "datasets/nesdis_ease2_latlon_1k/dmp.html#roles-and-responsibilities",
    "title": "Data Management:  nesdis_blendednesdis_ease2_latlon_nhem_1k, nesdis_ease2_latlon_shem_1k",
    "section": "",
    "text": "The PolarWatch Operations Manager is tasked with the implementation, documentation, and periodic updating of the Data Management Plan.\nThe data workflow is designed to be automated. This process is closely monitored, with automatic notifications being sent out in the event of any errors.\nThe documentation for internal data processing is accessible internally, ensuring that relevant team members can access it as needed. Additionally, all scripts associated with this processing are stored in a private repository."
  },
  {
    "objectID": "guidelines/metadata.html",
    "href": "guidelines/metadata.html",
    "title": "PolarWatch Metadata Guidelines",
    "section": "",
    "text": "Updated March 20, 2024\n\nHere are the metadata guidelines for data products intended for hosting on the PolarWatch ERDDAP Server. The metadata attributes and descriptions are created following the widely recognized industry convention standards, as indicated in the Standard column.\n\nAttribute Convention for Data Discovery(ACDD)\nGlobal Change Master Directory (GCMD)\nNetCDF Climate and Forecast (CF)\nNational Centers for Environmental Information (NCEI)\n\nLink to a template (excel sheet)\nFor any questions or assistance, please contact PolarWatch Ops Manager at polar.watch@noaa.gov\n\n\nGlobal attributes provide information about the data set.\n\n\n\n\n\n\n\n\n\n\nAttribute Name\nDescription\nStandards\n\n\n\n\ntitle\nA short phrase or sentence describing the dataset. In many discovery systems, the title will be displayed in the results list from a search, and therefore should be human readable and reasonable to display in a list of such names. This attribute is also recommended by the NetCDF Users Guide and the CF conventions.\nACDD\n\n\nsummary\nA paragraph describing the dataset, analogous to an abstract for a paper.\nACDD\n\n\nkeywords\n\nACDD, GCMD\n\n\nConventions\nA comma-separated list of the conventions that are followed by the dataset. For files that follow this version of ACDD, include the string ‘ACDD-1.3’. (This attribute is described in the NetCDF Users Guide.)\nACDD, CF\n\n\n\n\n\n\n\n\n\nAttribute Name\nDescription\nStandards\n\n\n\n\nncei_template_version\n\nNCEI\n\n\nid\nAn identifier for the data set, provided by and unique within its naming authority. The combination of the “naming authority” and the “id” should be globally unique, but the id can be globally unique by itself also. IDs can be URLs, URNs, DOIs, meaningful text strings, a local key, or any other unique string of characters. The id should not include white space characters.\nACDD\n\n\nnaming_authority\nThe organization that provides the initial id (see above) for the dataset. The naming authority should be uniquely specified by this attribute. We recommend using reverse-DNS naming for the naming authority; URIs are also acceptable. Example: ‘edu.ucar.unidata’.\nACDD\n\n\nhistory\nProvides an audit trail for modifications to the original data. This attribute is also in the NetCDF Users Guide: ‘This is a character array with a line for each invocation of a program that has modified the dataset. Well-behaved generic netCDF applications should append a line containing: date, time of day, user name, program name and command arguments.’ To include a more complete description you can append a reference to an ISO Lineage entity; see NOAA EDM ISO Lineage guidance.\nACDD\n\n\nsource\nThe method of production of the original data. If it was model-generated, source should name the model and its version. If it is observational, source should characterize it. This attribute is defined in the CF Conventions. Examples: ‘temperature from CTD #1234’; ‘world model v.0.1’.\nACDD\n\n\nprocessing_level\nA textual description of the processing (or quality control) level of the data.\nACDD\n\n\ncomment\nMiscellaneous information about the data, not captured elsewhere. This attribute is defined in the CF Conventions.\nACDD\n\n\nacknowledgement\nProvide the URL to a standard or specific license, enter “Freely Distributed” or “None”, or describe any restrictions to data access and distribution in free text.\nACDD\n\n\nlicense\nCreative Commons Universal Public Domain Dedication (CC0-1.0) for All Internal NOAA Source Data that are appropriate for public release with no restrictions on use … should be formally dedicated to the public domain using the Creative Commons Universal Public Domain Dedication (CC0-1.0), which provides legal confirmation that the data may be used by anyone, for any purpose.\nACDD\n\n\nstandard_name_vocabulary\nThe name and version of the controlled vocabulary from which variable standard names are taken. (Values for any standard_name attribute must come from the CF Standard Names vocabulary for the data file or product to comply with CF.) Example: ‘CF Standard Name Table v27’.\nACDD\n\n\ndate_created\nThe date on which this version of the data was created. (Modification of values implies a new version, hence this would be assigned the date of the most recent values modification.) Metadata changes are not considered when assigning the date_created. The ISO 8601:2004 extended date format is recommended, as described in the Attribute Content Guidance section.\nACDD\n\n\ncreator_name\nThe name of the person (or other creator type specified by the creator_type attribute) principally responsible for creating this data.\nACDD\n\n\ncreator_email\nThe email address of the person (or other creator type specified by the creator_type attribute) principally responsible for creating this data.\nACDD\n\n\ncreator_url\nThe URL of the person (or other creator type specified by the creator_type attribute) principally responsible for creating this data.\nACDD\n\n\ninstitution\nThe name of the institution principally responsible for originating this data. This attribute is recommended by the CF convention.\nACDD\n\n\nproject\nThe name of the project(s) principally responsible for originating this data. Multiple projects can be separated by commas, as described under Attribute Content Guidelines. Examples: ‘PATMOS-X’, ‘Extended Continental Shelf Project’.\nACDD\n\n\npublisher_name\nThe name of the person (or other entity specified by the publisher_type attribute) responsible for publishing the data file or product to users, with its current metadata and format.\nACDD\n\n\npublisher_email\nThe email address of the person (or other entity specified by the publisher_type attribute) responsible for publishing the data file or product to users, with its current metadata and format.\nACDD\n\n\npublisher_url\nThe URL of the person (or other entity specified by the publisher_type attribute) responsible for publishing the data file or product to users, with its current metadata and format.\nACDD\n\n\ngeospatial_bounds\nDescribes the data’s 2D or 3D geospatial extent in OGC’s Well-Known Text (WKT) Geometry format (reference the OGC Simple Feature Access (SFA) specification). The meaning and order of values for each point’s coordinates depends on the coordinate reference system (CRS). The ACDD default is 2D geometry in the EPSG:4326 coordinate reference system. The default may be overridden with geospatial_bounds_crs and geospatial_bounds_vertical_crs (see those attributes). EPSG:4326 coordinate values are latitude (decimal degrees_north) and longitude (decimal degrees_east), in that order. Longitude values in the default case are limited to the [-180, 180) range. Example: ‘POLYGON ((40.26 -111.29, 41.26 -111.29, 41.26 -110.29, 40.26 -110.29, 40.26 -111.29))’.\nACDD\n\n\ngeospatial_bounds_crs\nThe coordinate reference system (CRS) of the point coordinates in the geospatial_bounds attribute. This CRS may be 2-dimensional or 3-dimensional, but together with geospatial_bounds_vertical_crs, if that attribute is supplied, must match the dimensionality, order, and meaning of point coordinate values in the geospatial_bounds attribute. If geospatial_bounds_vertical_crs is also present then this attribute must only specify a 2D CRS. EPSG CRSs are strongly recommended. If this attribute is not specified, the CRS is assumed to be EPSG:4326. Examples: ‘EPSG:4979’ (the 3D WGS84 CRS), ‘EPSG:4047’.\nACDD\n\n\ngeospatial_bounds_vertical_crs\nThe vertical coordinate reference system (CRS) for the Z axis of the point coordinates in the geospatial_bounds attribute. This attribute cannot be used if the CRS in geospatial_bounds_crs is 3-dimensional; to use this attribute, geospatial_bounds_crs must exist and specify a 2D CRS. EPSG CRSs are strongly recommended. There is no default for this attribute when not specified. Examples: ‘EPSG:5829’ (instantaneous height above sea level), “EPSG:5831” (instantaneous depth below sea level), or ‘EPSG:5703’ (NAVD88 height).\nACDD\n\n\ngeospatial_lat_min\nDescribes a simple lower latitude limit; may be part of a 2- or 3-dimensional bounding region. Geospatial_lat_min specifies the southernmost latitude covered by the dataset.\nACDD\n\n\ngeospatial_lat_max\nDescribes a simple upper latitude limit; may be part of a 2- or 3-dimensional bounding region. Geospatial_lat_max specifies the northernmost latitude covered by the dataset.\nACDD\n\n\ngeospatial_lon_min\nDescribes a simple longitude limit; may be part of a 2- or 3-dimensional bounding region. geospatial_lon_min specifies the westernmost longitude covered by the dataset. See also geospatial_lon_max.\nACDD\n\n\ngeospatial_lon_max\nDescribes a simple longitude limit; may be part of a 2- or 3-dimensional bounding region. geospatial_lon_max specifies the easternmost longitude covered by the dataset. Cases where geospatial_lon_min is greater than geospatial_lon_max indicate the bounding box extends from geospatial_lon_max, through the longitude range discontinuity meridian (either the antimeridian for -180:180 values, or Prime Meridian for 0:360 values), to geospatial_lon_min; for example, geospatial_lon_min=170 and geospatial_lon_max=-175 incorporates 15 degrees of longitude (ranges 170 to 180 and -180 to -175).\nACDD\n\n\ngeospatial_vertical_min\nDescribes the numerically smaller vertical limit; may be part of a 2- or 3-dimensional bounding region. See geospatial_vertical_positive and geospatial_vertical_units.\nACDD\n\n\ngeospatial_vertical_max\nDescribes the numerically larger vertical limit; may be part of a 2- or 3-dimensional bounding region. See geospatial_vertical_positive and geospatial_vertical_units.\nACDD\n\n\ngeospatial_vertical_positive\nOne of ‘up’ or ‘down’. If up, vertical values are interpreted as ‘altitude’, with negative values corresponding to below the reference datum (e.g., under water). If down, vertical values are interpreted as ‘depth’, positive values correspond to below the reference datum. Note that if geospatial_vertical_positive is down (‘depth’ orientation), the geospatial_vertical_min attribute specifies the data’s vertical location furthest from the earth’s center, and the geospatial_vertical_max attribute specifies the location closest to the earth’s center.\nACDD\n\n\ntime_coverage_start\nDescribes the time of the first data point in the data set. Use ISO 8601:2004 date format, preferably the extended format as recommended in the Attribute Content Guidance section.\nACDD\n\n\ntime_coverage_end\nDescribes the time of the last data point in the data set. Use ISO 8601:2004 date format, preferably the extended format as recommended in the Attribute Content Guidance section.\nACDD\n\n\ntime_coverage_duration\nDescribes the duration of the data set. Use ISO 8601:2004 duration format, preferably the extended format as recommended in the Attribute Content Guidance section.\nACDD\n\n\ntime_coverage_resolution\nDescribes the targeted time period between each value in the data set. Use ISO 8601:2004 duration format, preferably the extended format as recommended in the Attribute Content Guidance section.\nACDD\n\n\n\n\n\n\n\n\n\nAttribute Name\nDescription\nStandards\n\n\n\n\ncreator_type\nSpecifies type of creator with one of the following: ‘person’, ‘group’, ‘institution’, or ‘position’. If this attribute is not specified, the creator is assumed to be a person.\nACDD\n\n\ncreator_institution\nThe institution of the creator; should uniquely identify the creator’s institution. This attribute’s value should be specified even if it matches the value of publisher_institution, or if creator_type is institution.\nACDD\n\n\npublisher_type\nSpecifies type of publisher with one of the following: ‘person’, ‘group’, ‘institution’, or ‘position’. If this attribute is not specified, the publisher is assumed to be a person.\nACDD\n\n\npublisher_institution\nThe institution that presented the data file or equivalent product to users; should uniquely identify the institution. If publisher_type is institution, this should have the same value as publisher_name.\nACDD\n\n\nprogram\nThe overarching program(s) of which the dataset is a part. A program consists of a set (or portfolio) of related and possibly interdependent projects that meet an overarching objective. Examples: ‘GHRSST’, ‘NOAA CDR’, ‘NASA EOS’, ‘JPSS’, ‘GOES-R’.\nACDD\n\n\ncontributor_name\nThe name of any individuals, projects, or institutions that contributed to the creation of this data. May be presented as free text, or in a structured format compatible with conversion to ncML (e.g., insensitive to changes in whitespace, including end-of-line characters).\nACDD\n\n\ncontributor_role\nThe role of any individuals, projects, or institutions that contributed to the creation of this data. May be presented as free text, or in a structured format compatible with conversion to ncML (e.g., insensitive to changes in whitespace, including end-of-line characters). Multiple roles should be presented in the same order and number as the names in contributor_names.\nACDD\n\n\ngeospatial_lat_units\nUnits for the latitude axis described in “geospatial_lat_min” and “geospatial_lat_max” attributes. These are presumed to be “degree_north”; other options from udunits may be specified instead.\nACDD\n\n\ngeospatial_lat_resolution\nInformation about the targeted spacing of points in latitude. Recommend describing resolution as a number value followed by the units. Examples: ‘100 meters’, ‘0.1 degree’\nACDD\n\n\ngeospatial_lon_units\nUnits for the longitude axis described in “geospatial_lon_min” and “geospatial_lon_max” attributes. These are presumed to be “degree_east”; other options from udunits may be specified instead.\nACDD\n\n\ngeospatial_lon_resolution\nInformation about the targeted spacing of points in longitude. Recommend describing resolution as a number value followed by units. Examples: ‘100 meters’, ‘0.1 degree’\nACDD\n\n\ngeospatial_vertical_units\nUnits for the vertical axis described in “geospatial_vertical_min” and “geospatial_vertical_max” attributes. The default is EPSG:4979 (height above the ellipsoid, in meters); other vertical coordinate reference systems may be specified. Note that the common oceanographic practice of using pressure for a vertical coordinate, while not strictly a depth, can be specified using the unit bar. Examples: ‘EPSG:5829’ (instantaneous height above sea level), ‘EPSG:5831’ (instantaneous depth below sea level).\nACDD\n\n\ngeospatial_vertical_resolution\nInformation about the targeted vertical spacing of points. Example: ‘25 meters’\nACDD\n\n\ndate_modified\nThe date on which the data was last modified. Note that this applies just to the data, not the metadata. The ISO 8601:2004 extended date format is recommended, as described in the Attributes Content Guidance section.\nACDD\n\n\ndate_issued\nThe date on which this data (including all modifications) was formally issued (i.e., made available to a wider audience). Note that these apply just to the data, not the metadata. The ISO 8601:2004 extended date format is recommended, as described in the Attributes Content Guidance section.\nACDD\n\n\ndate_metadata_modified\nThe date on which the metadata was last modified. The ISO 8601:2004 extended date format is recommended, as described in the Attributes Content Guidance section.\nACDD\n\n\nproduct_version\nVersion identifier of the data file or product as assigned by the data creator. For example, a new algorithm or methodology could result in a new product_version.\nACDD\n\n\nkeywords_vocabulary\nIf you are using a controlled vocabulary for the words/phrases in your “keywords” attribute, this is the unique name or identifier of the vocabulary from which keywords are taken. If more than one keyword vocabulary is used, each may be presented with a prefix and a following comma, so that keywords may optionally be prefixed with the controlled vocabulary key. Example: ‘GCMD:GCMD Keywords, CF:NetCDF COARDS Climate and Forecast Standard Names’.\nACDD\n\n\nplatform\nName of the platform(s) that supported the sensor data used to create this data set or product. Platforms can be of any type, including satellite, ship, station, aircraft or other. Indicate controlled vocabulary used in platform_vocabulary.\nACDD\n\n\nplatform_vocabulary\nControlled vocabulary for the names used in the “platform” attribute.\nACDD\n\n\ninstrument\nName of the contributing instrument(s) or sensor(s) used to create this data set or product. Indicate controlled vocabulary used in instrument_vocabulary.\nACDD\n\n\ninstrument_vocabulary\nControlled vocabulary for the names used in the “instrument” attribute.\nACDD\n\n\ncdm_data_type\nThe data type, as derived from Unidata’s Common Data Model Scientific Data types and understood by THREDDS. (This is a THREDDS “dataType”, and is different from the CF NetCDF attribute ‘featureType’, which indicates a Discrete Sampling Geometry file in CF.)\nACDD\n\n\nmetadata_link\nA URL that gives the location of more complete metadata. A persistent URL is recommended for this attribute.\nACDD\n\n\nreferences\nPublished or web-based references that describe the data or methods used to produce it. Recommend URIs (such as a URL or DOI) for papers or other references. This attribute is defined in the CF conventions.\nCF, ACDD\n\n\n\n\n\n\n\nVariable attributes provide detailed information about each individual variable within a dataset\n\n\n\n\n\nAttribute Name\nDescription\nStandards\n\n\n\n\nlong_name\nA long descriptive name for the variable (not necessarily from a controlled vocabulary). This attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\nstandard_name\nA long descriptive name for the variable taken from a controlled vocabulary of variable names. We recommend using the CF convention and the variable names from the CF standard name table. This attribute is recommended by the CF convention.\nCF, ACDD\n\n\nunits\nThe units of the variable’s data values. This attribute value should be a valid udunits string. The “units” attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\ncoverage_content_type\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\nioos_category\nhttps://mmisw.org/ont/ioos/category\n\n\n\n\n\n\n\n\nSpatial reference attributes are highly recommended for datasets distributed with projected coordinates.\n\n\n\n\n\n\n\n\n\n\nAttribute Name\nDescription\nStandards\n\n\n\n\ngrid_mapping_name\nA long descriptive name for the variable (not necessarily from a controlled vocabulary). This attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\ncrs\nA long descriptive name for the variable taken from a controlled vocabulary of variable names. We recommend using the CF convention and the variable names from the CF standard name table. This attribute is recommended by the CF convention.\nCF, ACDD\n\n\ncrs_proj4text\nThe units of the variable’s data values. This attribute value should be a valid udunits string. The “units” attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\ncrs_spatial_ref\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\ncrs_units\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\nearth_radius\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\ninverse_flattening\nA long descriptive name for the variable (not necessarily from a controlled vocabulary). This attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\nlongitude_of_prime_meridian\nA long descriptive name for the variable taken from a controlled vocabulary of variable names. We recommend using the CF convention and the variable names from the CF standard name table. This attribute is recommended by the CF convention.\nCF, ACDD\n\n\nprime_meridian_name\nThe units of the variable’s data values. This attribute value should be a valid udunits string. The “units” attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\nreference_ellipsoid_name\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\nsemi_major_axis\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\nsemi_minor_axis\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\n\n\n\n\n\n\n\n\ndate logged\nactivity\n\n\n\n\n03/20/2024\ncontent uploaded to Github\n\n\n04/11/2024\nadded spatial reference attributes\n\n\n07/30/2024\nadded links for various standards"
  },
  {
    "objectID": "guidelines/metadata.html#global-attributes",
    "href": "guidelines/metadata.html#global-attributes",
    "title": "PolarWatch Metadata Guidelines",
    "section": "",
    "text": "Global attributes provide information about the data set.\n\n\n\n\n\n\n\n\n\n\nAttribute Name\nDescription\nStandards\n\n\n\n\ntitle\nA short phrase or sentence describing the dataset. In many discovery systems, the title will be displayed in the results list from a search, and therefore should be human readable and reasonable to display in a list of such names. This attribute is also recommended by the NetCDF Users Guide and the CF conventions.\nACDD\n\n\nsummary\nA paragraph describing the dataset, analogous to an abstract for a paper.\nACDD\n\n\nkeywords\n\nACDD, GCMD\n\n\nConventions\nA comma-separated list of the conventions that are followed by the dataset. For files that follow this version of ACDD, include the string ‘ACDD-1.3’. (This attribute is described in the NetCDF Users Guide.)\nACDD, CF\n\n\n\n\n\n\n\n\n\nAttribute Name\nDescription\nStandards\n\n\n\n\nncei_template_version\n\nNCEI\n\n\nid\nAn identifier for the data set, provided by and unique within its naming authority. The combination of the “naming authority” and the “id” should be globally unique, but the id can be globally unique by itself also. IDs can be URLs, URNs, DOIs, meaningful text strings, a local key, or any other unique string of characters. The id should not include white space characters.\nACDD\n\n\nnaming_authority\nThe organization that provides the initial id (see above) for the dataset. The naming authority should be uniquely specified by this attribute. We recommend using reverse-DNS naming for the naming authority; URIs are also acceptable. Example: ‘edu.ucar.unidata’.\nACDD\n\n\nhistory\nProvides an audit trail for modifications to the original data. This attribute is also in the NetCDF Users Guide: ‘This is a character array with a line for each invocation of a program that has modified the dataset. Well-behaved generic netCDF applications should append a line containing: date, time of day, user name, program name and command arguments.’ To include a more complete description you can append a reference to an ISO Lineage entity; see NOAA EDM ISO Lineage guidance.\nACDD\n\n\nsource\nThe method of production of the original data. If it was model-generated, source should name the model and its version. If it is observational, source should characterize it. This attribute is defined in the CF Conventions. Examples: ‘temperature from CTD #1234’; ‘world model v.0.1’.\nACDD\n\n\nprocessing_level\nA textual description of the processing (or quality control) level of the data.\nACDD\n\n\ncomment\nMiscellaneous information about the data, not captured elsewhere. This attribute is defined in the CF Conventions.\nACDD\n\n\nacknowledgement\nProvide the URL to a standard or specific license, enter “Freely Distributed” or “None”, or describe any restrictions to data access and distribution in free text.\nACDD\n\n\nlicense\nCreative Commons Universal Public Domain Dedication (CC0-1.0) for All Internal NOAA Source Data that are appropriate for public release with no restrictions on use … should be formally dedicated to the public domain using the Creative Commons Universal Public Domain Dedication (CC0-1.0), which provides legal confirmation that the data may be used by anyone, for any purpose.\nACDD\n\n\nstandard_name_vocabulary\nThe name and version of the controlled vocabulary from which variable standard names are taken. (Values for any standard_name attribute must come from the CF Standard Names vocabulary for the data file or product to comply with CF.) Example: ‘CF Standard Name Table v27’.\nACDD\n\n\ndate_created\nThe date on which this version of the data was created. (Modification of values implies a new version, hence this would be assigned the date of the most recent values modification.) Metadata changes are not considered when assigning the date_created. The ISO 8601:2004 extended date format is recommended, as described in the Attribute Content Guidance section.\nACDD\n\n\ncreator_name\nThe name of the person (or other creator type specified by the creator_type attribute) principally responsible for creating this data.\nACDD\n\n\ncreator_email\nThe email address of the person (or other creator type specified by the creator_type attribute) principally responsible for creating this data.\nACDD\n\n\ncreator_url\nThe URL of the person (or other creator type specified by the creator_type attribute) principally responsible for creating this data.\nACDD\n\n\ninstitution\nThe name of the institution principally responsible for originating this data. This attribute is recommended by the CF convention.\nACDD\n\n\nproject\nThe name of the project(s) principally responsible for originating this data. Multiple projects can be separated by commas, as described under Attribute Content Guidelines. Examples: ‘PATMOS-X’, ‘Extended Continental Shelf Project’.\nACDD\n\n\npublisher_name\nThe name of the person (or other entity specified by the publisher_type attribute) responsible for publishing the data file or product to users, with its current metadata and format.\nACDD\n\n\npublisher_email\nThe email address of the person (or other entity specified by the publisher_type attribute) responsible for publishing the data file or product to users, with its current metadata and format.\nACDD\n\n\npublisher_url\nThe URL of the person (or other entity specified by the publisher_type attribute) responsible for publishing the data file or product to users, with its current metadata and format.\nACDD\n\n\ngeospatial_bounds\nDescribes the data’s 2D or 3D geospatial extent in OGC’s Well-Known Text (WKT) Geometry format (reference the OGC Simple Feature Access (SFA) specification). The meaning and order of values for each point’s coordinates depends on the coordinate reference system (CRS). The ACDD default is 2D geometry in the EPSG:4326 coordinate reference system. The default may be overridden with geospatial_bounds_crs and geospatial_bounds_vertical_crs (see those attributes). EPSG:4326 coordinate values are latitude (decimal degrees_north) and longitude (decimal degrees_east), in that order. Longitude values in the default case are limited to the [-180, 180) range. Example: ‘POLYGON ((40.26 -111.29, 41.26 -111.29, 41.26 -110.29, 40.26 -110.29, 40.26 -111.29))’.\nACDD\n\n\ngeospatial_bounds_crs\nThe coordinate reference system (CRS) of the point coordinates in the geospatial_bounds attribute. This CRS may be 2-dimensional or 3-dimensional, but together with geospatial_bounds_vertical_crs, if that attribute is supplied, must match the dimensionality, order, and meaning of point coordinate values in the geospatial_bounds attribute. If geospatial_bounds_vertical_crs is also present then this attribute must only specify a 2D CRS. EPSG CRSs are strongly recommended. If this attribute is not specified, the CRS is assumed to be EPSG:4326. Examples: ‘EPSG:4979’ (the 3D WGS84 CRS), ‘EPSG:4047’.\nACDD\n\n\ngeospatial_bounds_vertical_crs\nThe vertical coordinate reference system (CRS) for the Z axis of the point coordinates in the geospatial_bounds attribute. This attribute cannot be used if the CRS in geospatial_bounds_crs is 3-dimensional; to use this attribute, geospatial_bounds_crs must exist and specify a 2D CRS. EPSG CRSs are strongly recommended. There is no default for this attribute when not specified. Examples: ‘EPSG:5829’ (instantaneous height above sea level), “EPSG:5831” (instantaneous depth below sea level), or ‘EPSG:5703’ (NAVD88 height).\nACDD\n\n\ngeospatial_lat_min\nDescribes a simple lower latitude limit; may be part of a 2- or 3-dimensional bounding region. Geospatial_lat_min specifies the southernmost latitude covered by the dataset.\nACDD\n\n\ngeospatial_lat_max\nDescribes a simple upper latitude limit; may be part of a 2- or 3-dimensional bounding region. Geospatial_lat_max specifies the northernmost latitude covered by the dataset.\nACDD\n\n\ngeospatial_lon_min\nDescribes a simple longitude limit; may be part of a 2- or 3-dimensional bounding region. geospatial_lon_min specifies the westernmost longitude covered by the dataset. See also geospatial_lon_max.\nACDD\n\n\ngeospatial_lon_max\nDescribes a simple longitude limit; may be part of a 2- or 3-dimensional bounding region. geospatial_lon_max specifies the easternmost longitude covered by the dataset. Cases where geospatial_lon_min is greater than geospatial_lon_max indicate the bounding box extends from geospatial_lon_max, through the longitude range discontinuity meridian (either the antimeridian for -180:180 values, or Prime Meridian for 0:360 values), to geospatial_lon_min; for example, geospatial_lon_min=170 and geospatial_lon_max=-175 incorporates 15 degrees of longitude (ranges 170 to 180 and -180 to -175).\nACDD\n\n\ngeospatial_vertical_min\nDescribes the numerically smaller vertical limit; may be part of a 2- or 3-dimensional bounding region. See geospatial_vertical_positive and geospatial_vertical_units.\nACDD\n\n\ngeospatial_vertical_max\nDescribes the numerically larger vertical limit; may be part of a 2- or 3-dimensional bounding region. See geospatial_vertical_positive and geospatial_vertical_units.\nACDD\n\n\ngeospatial_vertical_positive\nOne of ‘up’ or ‘down’. If up, vertical values are interpreted as ‘altitude’, with negative values corresponding to below the reference datum (e.g., under water). If down, vertical values are interpreted as ‘depth’, positive values correspond to below the reference datum. Note that if geospatial_vertical_positive is down (‘depth’ orientation), the geospatial_vertical_min attribute specifies the data’s vertical location furthest from the earth’s center, and the geospatial_vertical_max attribute specifies the location closest to the earth’s center.\nACDD\n\n\ntime_coverage_start\nDescribes the time of the first data point in the data set. Use ISO 8601:2004 date format, preferably the extended format as recommended in the Attribute Content Guidance section.\nACDD\n\n\ntime_coverage_end\nDescribes the time of the last data point in the data set. Use ISO 8601:2004 date format, preferably the extended format as recommended in the Attribute Content Guidance section.\nACDD\n\n\ntime_coverage_duration\nDescribes the duration of the data set. Use ISO 8601:2004 duration format, preferably the extended format as recommended in the Attribute Content Guidance section.\nACDD\n\n\ntime_coverage_resolution\nDescribes the targeted time period between each value in the data set. Use ISO 8601:2004 duration format, preferably the extended format as recommended in the Attribute Content Guidance section.\nACDD\n\n\n\n\n\n\n\n\n\nAttribute Name\nDescription\nStandards\n\n\n\n\ncreator_type\nSpecifies type of creator with one of the following: ‘person’, ‘group’, ‘institution’, or ‘position’. If this attribute is not specified, the creator is assumed to be a person.\nACDD\n\n\ncreator_institution\nThe institution of the creator; should uniquely identify the creator’s institution. This attribute’s value should be specified even if it matches the value of publisher_institution, or if creator_type is institution.\nACDD\n\n\npublisher_type\nSpecifies type of publisher with one of the following: ‘person’, ‘group’, ‘institution’, or ‘position’. If this attribute is not specified, the publisher is assumed to be a person.\nACDD\n\n\npublisher_institution\nThe institution that presented the data file or equivalent product to users; should uniquely identify the institution. If publisher_type is institution, this should have the same value as publisher_name.\nACDD\n\n\nprogram\nThe overarching program(s) of which the dataset is a part. A program consists of a set (or portfolio) of related and possibly interdependent projects that meet an overarching objective. Examples: ‘GHRSST’, ‘NOAA CDR’, ‘NASA EOS’, ‘JPSS’, ‘GOES-R’.\nACDD\n\n\ncontributor_name\nThe name of any individuals, projects, or institutions that contributed to the creation of this data. May be presented as free text, or in a structured format compatible with conversion to ncML (e.g., insensitive to changes in whitespace, including end-of-line characters).\nACDD\n\n\ncontributor_role\nThe role of any individuals, projects, or institutions that contributed to the creation of this data. May be presented as free text, or in a structured format compatible with conversion to ncML (e.g., insensitive to changes in whitespace, including end-of-line characters). Multiple roles should be presented in the same order and number as the names in contributor_names.\nACDD\n\n\ngeospatial_lat_units\nUnits for the latitude axis described in “geospatial_lat_min” and “geospatial_lat_max” attributes. These are presumed to be “degree_north”; other options from udunits may be specified instead.\nACDD\n\n\ngeospatial_lat_resolution\nInformation about the targeted spacing of points in latitude. Recommend describing resolution as a number value followed by the units. Examples: ‘100 meters’, ‘0.1 degree’\nACDD\n\n\ngeospatial_lon_units\nUnits for the longitude axis described in “geospatial_lon_min” and “geospatial_lon_max” attributes. These are presumed to be “degree_east”; other options from udunits may be specified instead.\nACDD\n\n\ngeospatial_lon_resolution\nInformation about the targeted spacing of points in longitude. Recommend describing resolution as a number value followed by units. Examples: ‘100 meters’, ‘0.1 degree’\nACDD\n\n\ngeospatial_vertical_units\nUnits for the vertical axis described in “geospatial_vertical_min” and “geospatial_vertical_max” attributes. The default is EPSG:4979 (height above the ellipsoid, in meters); other vertical coordinate reference systems may be specified. Note that the common oceanographic practice of using pressure for a vertical coordinate, while not strictly a depth, can be specified using the unit bar. Examples: ‘EPSG:5829’ (instantaneous height above sea level), ‘EPSG:5831’ (instantaneous depth below sea level).\nACDD\n\n\ngeospatial_vertical_resolution\nInformation about the targeted vertical spacing of points. Example: ‘25 meters’\nACDD\n\n\ndate_modified\nThe date on which the data was last modified. Note that this applies just to the data, not the metadata. The ISO 8601:2004 extended date format is recommended, as described in the Attributes Content Guidance section.\nACDD\n\n\ndate_issued\nThe date on which this data (including all modifications) was formally issued (i.e., made available to a wider audience). Note that these apply just to the data, not the metadata. The ISO 8601:2004 extended date format is recommended, as described in the Attributes Content Guidance section.\nACDD\n\n\ndate_metadata_modified\nThe date on which the metadata was last modified. The ISO 8601:2004 extended date format is recommended, as described in the Attributes Content Guidance section.\nACDD\n\n\nproduct_version\nVersion identifier of the data file or product as assigned by the data creator. For example, a new algorithm or methodology could result in a new product_version.\nACDD\n\n\nkeywords_vocabulary\nIf you are using a controlled vocabulary for the words/phrases in your “keywords” attribute, this is the unique name or identifier of the vocabulary from which keywords are taken. If more than one keyword vocabulary is used, each may be presented with a prefix and a following comma, so that keywords may optionally be prefixed with the controlled vocabulary key. Example: ‘GCMD:GCMD Keywords, CF:NetCDF COARDS Climate and Forecast Standard Names’.\nACDD\n\n\nplatform\nName of the platform(s) that supported the sensor data used to create this data set or product. Platforms can be of any type, including satellite, ship, station, aircraft or other. Indicate controlled vocabulary used in platform_vocabulary.\nACDD\n\n\nplatform_vocabulary\nControlled vocabulary for the names used in the “platform” attribute.\nACDD\n\n\ninstrument\nName of the contributing instrument(s) or sensor(s) used to create this data set or product. Indicate controlled vocabulary used in instrument_vocabulary.\nACDD\n\n\ninstrument_vocabulary\nControlled vocabulary for the names used in the “instrument” attribute.\nACDD\n\n\ncdm_data_type\nThe data type, as derived from Unidata’s Common Data Model Scientific Data types and understood by THREDDS. (This is a THREDDS “dataType”, and is different from the CF NetCDF attribute ‘featureType’, which indicates a Discrete Sampling Geometry file in CF.)\nACDD\n\n\nmetadata_link\nA URL that gives the location of more complete metadata. A persistent URL is recommended for this attribute.\nACDD\n\n\nreferences\nPublished or web-based references that describe the data or methods used to produce it. Recommend URIs (such as a URL or DOI) for papers or other references. This attribute is defined in the CF conventions.\nCF, ACDD"
  },
  {
    "objectID": "guidelines/metadata.html#variable-attributes",
    "href": "guidelines/metadata.html#variable-attributes",
    "title": "PolarWatch Metadata Guidelines",
    "section": "",
    "text": "Variable attributes provide detailed information about each individual variable within a dataset\n\n\n\n\n\nAttribute Name\nDescription\nStandards\n\n\n\n\nlong_name\nA long descriptive name for the variable (not necessarily from a controlled vocabulary). This attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\nstandard_name\nA long descriptive name for the variable taken from a controlled vocabulary of variable names. We recommend using the CF convention and the variable names from the CF standard name table. This attribute is recommended by the CF convention.\nCF, ACDD\n\n\nunits\nThe units of the variable’s data values. This attribute value should be a valid udunits string. The “units” attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\ncoverage_content_type\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\nioos_category\nhttps://mmisw.org/ont/ioos/category"
  },
  {
    "objectID": "guidelines/metadata.html#spatial-reference",
    "href": "guidelines/metadata.html#spatial-reference",
    "title": "PolarWatch Metadata Guidelines",
    "section": "",
    "text": "Spatial reference attributes are highly recommended for datasets distributed with projected coordinates.\n\n\n\n\n\n\n\n\n\n\nAttribute Name\nDescription\nStandards\n\n\n\n\ngrid_mapping_name\nA long descriptive name for the variable (not necessarily from a controlled vocabulary). This attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\ncrs\nA long descriptive name for the variable taken from a controlled vocabulary of variable names. We recommend using the CF convention and the variable names from the CF standard name table. This attribute is recommended by the CF convention.\nCF, ACDD\n\n\ncrs_proj4text\nThe units of the variable’s data values. This attribute value should be a valid udunits string. The “units” attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\ncrs_spatial_ref\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\ncrs_units\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\nearth_radius\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\ninverse_flattening\nA long descriptive name for the variable (not necessarily from a controlled vocabulary). This attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\nlongitude_of_prime_meridian\nA long descriptive name for the variable taken from a controlled vocabulary of variable names. We recommend using the CF convention and the variable names from the CF standard name table. This attribute is recommended by the CF convention.\nCF, ACDD\n\n\nprime_meridian_name\nThe units of the variable’s data values. This attribute value should be a valid udunits string. The “units” attribute is recommended by the NetCDF Users Guide, the COARDS convention, and the CF convention.\nCF, ACDD\n\n\nreference_ellipsoid_name\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\nsemi_major_axis\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD\n\n\nsemi_minor_axis\nAn ISO 19115-1 code to indicate the source of the data (image, thematicClassification, physicalMeasurement, auxiliaryInformation, qualityInformation, referenceInformation, modelResult, or coordinate).\nACDD"
  },
  {
    "objectID": "guidelines/metadata.html#change-history",
    "href": "guidelines/metadata.html#change-history",
    "title": "PolarWatch Metadata Guidelines",
    "section": "",
    "text": "date logged\nactivity\n\n\n\n\n03/20/2024\ncontent uploaded to Github\n\n\n04/11/2024\nadded spatial reference attributes\n\n\n07/30/2024\nadded links for various standards"
  },
  {
    "objectID": "guidelines/dmp_template.html",
    "href": "guidelines/dmp_template.html",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "In support of Open Science and Open Data, PolarWatch plans to share Data Management Plan.\nSource: https://guides.library.oregonstate.edu/dmp/general#s-lg-box-7689540\nGeneral DMP template based on general NSF guidelines\n\n\nGive a short description of the data and materials collected and created, and amounts (if known).\n\nDescription of data to be produced (experimental, observational, raw or derived, physical collections, models, images, etc.)\nHow data will be acquired (When? Where? Methods?)\nHow data will be processed (software used, algorithms, workflows, protocols)\nFile types and formats (CSV, tab-delimited, proprietary formats, naming conventions)\nHow much data will be generated? (range is OK)\nExisting data: if existing data are used, what are their origins? Will your data be combined with existing data? What is the relationship between your and existing data?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data types and formats in the Research Data Services website.\n\n\n\n\n\nMetadata includes all of the contextual information that would be necessary for someone to understand, use or recreate your dataset (even many years from now). It may include methodological information, definition of variables, units, assumptions made, etc… Metadata can take many forms, from readme files manually created, to automatically generated metadata by sensors, to metadata recorded in a metadata standard. Recording part of the metadata in normalized schemas and metadata standards will enhance discoverability and make your metadata computer friendly.\n\nWhat metadata are needed\nAny details that make data understandable and useable\nHow metadata will be created and/or captured\nLab notebooks? GPS units? Auto-saved on instrument? Manually entered?\nWhat format will be used for metadata?\nStandards for community (EML, ISO 19115, Dublin Core, etc… .\nJustification for format chosen\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data documentation and metadata in the Research Data Services website. When possible use data standards and/or metadata standards. A list of research metadata standards compiled by the Research Data Alliance can be found here. If you chose not to use a metadata standard, consider structuring metadata in the research project with your own template.\n\n\n\n\n\n\nDescribe how the data will be stored.\nDescribe how the data will be backed up.\n\nWhich locations\nAutomatic or manual\nWho will be responsible\nHow will the data be recovered in the event of an accident\n\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about storage and backups in the Research Data Services website. Oregon State University offers several cloud storage options. Data storage options for diferent clasifications of data at Oregon State University can be found at the OSU Data Management, Classification and Incident Response Policy.\n\n\n\n\n\nThis section is very important. Your funding agency needs to see that you have thought carefully about how you will prepare (manage) your data for sharing and how you will share your data with the public in reasonable time after the conclusion of your project. If the data are of a sensitive nature - human subject concerns, potential patentability, species/ecological endangerment concerns – such that public access is inappropriate, address here the means by which granular control and access will be achieved (e.g. formal consent agreements; anonymization of data; restricted access, only available within a secure network).\n\n\n\n\n\n\nTip\n\n\n\nInformation about Intellectual Property and datasets in the Research Data Services website. OSU Data Management, Classification and Incident Response Policy defines three data categories: unrestricted, sensitive and confidential. The policy outlines baselines of care. Data Management Plans are written before IRB approval, so you may not know all the details about how your sensitive data will need to be managed. Having plans for data sharing before getting IRB approval may help you to write your consent forms taking your data sharing goals into consideration.\n\n\n\nHow will potential users find out about your data?\nWhen will you make the data available?\nHow will you make the data available? (include resources needed to make the data available: equipment, systems, expertise, etc.)\nWhat is the process for gaining access to the data? (by request, open-access repository, etc.)\nWill access be chargeable?\nWill you be using persistent identifiers (e.g. DOI) for your datasets?\nWill a data sharing agreement or similar be required to share the dataset?\nExplain how the policies & procedures you outlined above relate to the reuse and redistribution of your data. Identify who will be allowed to use your data, how they will be allowed to use it, and if they will be allowed to disseminate your data.\nWill any permission restrictions need to be placed on the data? If you will restrict access to certain users explain why. Are you going to attach any licenses to the dataset?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data sharing in the Research Data Services website. You are welcome to share your research data in OSU’s institutional repository, ScholarsArchive@OSU. ScholarsArchive@OSU is a digital repository that promises preservation, discoverability, and persistency of digital objects and is supported by the OSU Libraries & Press. All datasets deposited to ScholarsArchive@OSU will be assigned DOIs, and metadata for discoverability, usability, and administrative needs of the data. A list of repositories can be found in re3data.org. Make sure that you evaluate the reliability of a repository first, if you choose it from this website without knowing much about it.\n\n\n\n\n\nThis section should cover your long-term strategy for preserving the data produced during your project. See section on data archiving.\n\nWhat data will be preserved for the long-term?\nWhat is the long-term strategy for maintaining, curating and archiving the data?\nWhere will it be preserved?\nWhich archive/repository/database have you identified as a place to deposit data?\nWhat procedures does your intended long-term data storage facility have in place for preservation and backup?\nHow long will/should data be kept beyond the life of the project?\nData transformations/formats needed\nWhat transformations will be necessary to prepare data for preservation / data sharing?\nWhat metadata/ documentation will be submitted alongside the data or created on deposit/ transformation in order to make the data reusable?\nWhat related information will be deposited?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data archival and preservation in the Research Data Services website. You are welcome to preserve your research data in OSU’s institutional repository, ScholarsArchive@OSU. ScholarsArchive@OSU is a digital repository that promises preservation, discoverability, and persistency of digital objects and is supported by the OSU Libraries & Press. All datasets deposited to ScholarsArchive@OSU will be assigned DOIs, and metadata for discoverability, usability, and administrative needs of the data.\nSometimes the sharing and preservation section of a Data Management Plan overlap if you are using a repository as both a sharing and a preservation strategy.\n\n\n\n\n\n\nWho will be responsible for making sure that the Data Management Plan will be implemented?\nWho will perform each of the data management tasks (data collection, data assurance and quality control, data documentation, data archiving, etc.).\nWhat are the procedures in place that ensure that if one member of the team leaves the project data management tasks will still be performed?"
  },
  {
    "objectID": "guidelines/dmp_template.html#data-description",
    "href": "guidelines/dmp_template.html#data-description",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Give a short description of the data and materials collected and created, and amounts (if known).\n\nDescription of data to be produced (experimental, observational, raw or derived, physical collections, models, images, etc.)\nHow data will be acquired (When? Where? Methods?)\nHow data will be processed (software used, algorithms, workflows, protocols)\nFile types and formats (CSV, tab-delimited, proprietary formats, naming conventions)\nHow much data will be generated? (range is OK)\nExisting data: if existing data are used, what are their origins? Will your data be combined with existing data? What is the relationship between your and existing data?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data types and formats in the Research Data Services website."
  },
  {
    "objectID": "guidelines/dmp_template.html#metadata",
    "href": "guidelines/dmp_template.html#metadata",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Metadata includes all of the contextual information that would be necessary for someone to understand, use or recreate your dataset (even many years from now). It may include methodological information, definition of variables, units, assumptions made, etc… Metadata can take many forms, from readme files manually created, to automatically generated metadata by sensors, to metadata recorded in a metadata standard. Recording part of the metadata in normalized schemas and metadata standards will enhance discoverability and make your metadata computer friendly.\n\nWhat metadata are needed\nAny details that make data understandable and useable\nHow metadata will be created and/or captured\nLab notebooks? GPS units? Auto-saved on instrument? Manually entered?\nWhat format will be used for metadata?\nStandards for community (EML, ISO 19115, Dublin Core, etc… .\nJustification for format chosen\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data documentation and metadata in the Research Data Services website. When possible use data standards and/or metadata standards. A list of research metadata standards compiled by the Research Data Alliance can be found here. If you chose not to use a metadata standard, consider structuring metadata in the research project with your own template."
  },
  {
    "objectID": "guidelines/dmp_template.html#storage-and-backup",
    "href": "guidelines/dmp_template.html#storage-and-backup",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Describe how the data will be stored.\nDescribe how the data will be backed up.\n\nWhich locations\nAutomatic or manual\nWho will be responsible\nHow will the data be recovered in the event of an accident\n\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about storage and backups in the Research Data Services website. Oregon State University offers several cloud storage options. Data storage options for diferent clasifications of data at Oregon State University can be found at the OSU Data Management, Classification and Incident Response Policy."
  },
  {
    "objectID": "guidelines/dmp_template.html#policies-for-access-and-sharing",
    "href": "guidelines/dmp_template.html#policies-for-access-and-sharing",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "This section is very important. Your funding agency needs to see that you have thought carefully about how you will prepare (manage) your data for sharing and how you will share your data with the public in reasonable time after the conclusion of your project. If the data are of a sensitive nature - human subject concerns, potential patentability, species/ecological endangerment concerns – such that public access is inappropriate, address here the means by which granular control and access will be achieved (e.g. formal consent agreements; anonymization of data; restricted access, only available within a secure network).\n\n\n\n\n\n\nTip\n\n\n\nInformation about Intellectual Property and datasets in the Research Data Services website. OSU Data Management, Classification and Incident Response Policy defines three data categories: unrestricted, sensitive and confidential. The policy outlines baselines of care. Data Management Plans are written before IRB approval, so you may not know all the details about how your sensitive data will need to be managed. Having plans for data sharing before getting IRB approval may help you to write your consent forms taking your data sharing goals into consideration.\n\n\n\nHow will potential users find out about your data?\nWhen will you make the data available?\nHow will you make the data available? (include resources needed to make the data available: equipment, systems, expertise, etc.)\nWhat is the process for gaining access to the data? (by request, open-access repository, etc.)\nWill access be chargeable?\nWill you be using persistent identifiers (e.g. DOI) for your datasets?\nWill a data sharing agreement or similar be required to share the dataset?\nExplain how the policies & procedures you outlined above relate to the reuse and redistribution of your data. Identify who will be allowed to use your data, how they will be allowed to use it, and if they will be allowed to disseminate your data.\nWill any permission restrictions need to be placed on the data? If you will restrict access to certain users explain why. Are you going to attach any licenses to the dataset?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data sharing in the Research Data Services website. You are welcome to share your research data in OSU’s institutional repository, ScholarsArchive@OSU. ScholarsArchive@OSU is a digital repository that promises preservation, discoverability, and persistency of digital objects and is supported by the OSU Libraries & Press. All datasets deposited to ScholarsArchive@OSU will be assigned DOIs, and metadata for discoverability, usability, and administrative needs of the data. A list of repositories can be found in re3data.org. Make sure that you evaluate the reliability of a repository first, if you choose it from this website without knowing much about it."
  },
  {
    "objectID": "guidelines/dmp_template.html#plans-for-archiving-data-samples-and-other-research-products-and-for-preservation-of-access-to-them",
    "href": "guidelines/dmp_template.html#plans-for-archiving-data-samples-and-other-research-products-and-for-preservation-of-access-to-them",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "This section should cover your long-term strategy for preserving the data produced during your project. See section on data archiving.\n\nWhat data will be preserved for the long-term?\nWhat is the long-term strategy for maintaining, curating and archiving the data?\nWhere will it be preserved?\nWhich archive/repository/database have you identified as a place to deposit data?\nWhat procedures does your intended long-term data storage facility have in place for preservation and backup?\nHow long will/should data be kept beyond the life of the project?\nData transformations/formats needed\nWhat transformations will be necessary to prepare data for preservation / data sharing?\nWhat metadata/ documentation will be submitted alongside the data or created on deposit/ transformation in order to make the data reusable?\nWhat related information will be deposited?\n\n\n\n\n\n\n\nTip\n\n\n\nInformation about data archival and preservation in the Research Data Services website. You are welcome to preserve your research data in OSU’s institutional repository, ScholarsArchive@OSU. ScholarsArchive@OSU is a digital repository that promises preservation, discoverability, and persistency of digital objects and is supported by the OSU Libraries & Press. All datasets deposited to ScholarsArchive@OSU will be assigned DOIs, and metadata for discoverability, usability, and administrative needs of the data.\nSometimes the sharing and preservation section of a Data Management Plan overlap if you are using a repository as both a sharing and a preservation strategy."
  },
  {
    "objectID": "guidelines/dmp_template.html#roles-and-responsibilities",
    "href": "guidelines/dmp_template.html#roles-and-responsibilities",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "Who will be responsible for making sure that the Data Management Plan will be implemented?\nWho will perform each of the data management tasks (data collection, data assurance and quality control, data documentation, data archiving, etc.).\nWhat are the procedures in place that ensure that if one member of the team leaves the project data management tasks will still be performed?"
  },
  {
    "objectID": "guidelines/ai-ready-data-checklist-v.1.0.html",
    "href": "guidelines/ai-ready-data-checklist-v.1.0.html",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "Updated 04/03/2024\n\nSource: https://github.com/ESIPFed/data-readiness/blob/main/checklist-published/ai-ready-data-checklist-v.1.0.md\nThe checklist is developed using the 2019 draft readiness matrix developed by the Office of Science and Technology Policy Subcommittee on Open Science as a basis. The checklist has been improved based on further research and user feedback. Definitions for some concepts are listed at the end of this document. This checklist is developed through a collaboration of ESIP Data Readiness Cluster members include representatives from NOAA, NASA, USGS, and other organizations. The checklist will be updated periodically to reflect community feedback.\nLink to the google sheet\n\n\nIdeally for AI-ready assessment, a dataset should be defined as the minimum measurable bundle (i.e., a physical parameter/variable of observational datasets or model simulations). The assessment at this scale will enable better integration of data from different sources for research and development. However, it can be an intensive process for manual assessment without automation. Therefore, we recommend current assessments be done on the data file level. If the dataset has different versions, the checklist should be applied to each dataset type (e.g. raw, derived).\n\n\n\n\nESIP Data Readiness Cluster (2023): Checklist to Examine AI-readiness for Open Environmental Datasets v.1.0. ESIP. Online resource. https://doi.org/10.6084/m9.figshare.19983722.v1\n\n\n\n\nVersion: 1.0;\nLast updated: June 21, 2023.\n\n\n\n\n\nLink to the dataset landing page (questions below could be automatically filled from the landing page in the future)\n\nName of the dataset\nThe current version of the dataset\nPoint of contact for the dataset\nWhen was the dataset originally published?\n\nIs this raw data or a derived/processed data product? Raw/Derived\nIs this observational data, simulation/model output, or synthetic data? Observed/Modeled/Synthetic\nIs the data single-source or aggregated from several sources? Single-source/Aggregated\n\n\n\n\n\nQuestions on timeliness:\n\nWill the dataset be updated? Yes, it will be updated. / No, it will not be updated\nIf the data will be updated, how often will it be updated? [choose from]\n\nUpdated when new data are added.\n\nChoose the update frequency that best describes the dataset: near-real-time (irregularly) / hourly or sub-hourly / daily or sub-daily / weekly / monthly / yearly / longer than a year\nWill there be different stages of the update (e.g., updated with preliminary data first and replaced by a later update of the full record)? Yes/No/Not applicable.\n\nIf yes, what is the delay between different stages? [short answer]\n\n\nUpdated when a new version of the dataset is available.\n\nShould the new version of the dataset supersede the current version? Yes / No / Others\n\nProvide an explanation for “Others”\n\n\n\n\nQuestions on data completeness\n\nIs there any documentation about the completeness of the dataset? Yes / No\n\nIf yes, link to the report/document\n\nHow complete is the dataset compared to the expected spatial coverage? Complete / Partial / Unknown / Not applicable\nHow complete is the dataset compared to the expected temporal coverage? Complete / Partial / Unknown / Not applicable\n\nQuestions on data consistency\n\nIs this dataset self-consistent in that its units, data types, and parameter names do not change over time and space? Yes / No / Not applicable\nIs this dataset’s units, data types, and parameter names consistent with similar data collections? Yes / No / Not applicable\nAre there processes to monitor for units, data types, and parameter consistency? Yes / No / Not applicable\n\nIf yes, what measures are taken? Manual review / Automated review\n\n\nQuestions on data bias\n\nIs there known bias in the dataset? Yes / No\n\nIf yes, provide more information\n\nHave measures been taken to examine bias? Yes / No\n\nIf yes, what measures were used?\nIs the bias metrological traceable?\n\nIs there reported bias in the data? No known bias / Bias found and reported / No information available\n\n(optional) Link to the report/document on the bias\n(optional) Link to tools available to reduce bias\n(optional) Link to a bias-corrected or bias-reduced version of the dataset\n\nIs there quantitative information about data resolution in space and time? Yes / No / Not applicable\nAre there published data quality procedures or reports? Yes / No\n\nIf there is published quality information, please provide the link to the information.\n\nIs the provenance of the dataset tracked and documented? Yes / No / Not applicable\nAre there checksums / other checks for data integrity? Yes / No / Not applicable\nWhat is the size of the dataset? Depending on the resource, this might be total data volume, dimensionality, number of images, data files, table rows, image size, etc. [Short Answer]\n\n\n\n\n\n\nDoes the dataset metadata follow a community/domain standard or convention? Yes / No / Not applicable\n\nIf the metadata follows a community/domain standard, which standard is it? Select from a list [CF, …, TBD, others]\nIs the dataset metadata machine-readable? Yes / No / Not applicable\nDoes it include details on the spatial and temporal extent? Yes / No / Not applicable\n\nIs there a comprehensive data dictionary/codebook that describes what each element of the dataset means? parameters? Yes / No / Not applicable\n\nIs the data dictionary standardized? Yes / No / Not applicable\nIs the data dictionary machine-readable? Yes / No / Not applicable\nDo the parameters follow a defined standard? Yes / No / Not applicable\n\nIf the parameters follow a defined standard, which standard it is?\n\nAre parameters crosswalked in an ontology or common vocabulary (e.g. NIEM)? Yes / No / Not applicable\n\nDoes the dataset have a unique persistent identifier, e.g. DOI? Yes, [supply identifier] / No / Not applicable\nIs there contact information for subject-matter experts? Yes / No / Not applicable\nIs there a mechanism for user feedback and suggestions? Yes / No / Not applicable\nAre there example codes/notebooks/toolkits available showing how the data can be used? Yes / No / Not applicable\nWhat is the license for the data?\n\nPick from a list of data licenses + others + no official data license\nIs the license standardized and machine-readable (e.g. Creative Commons)? Yes / No / Not applicable\n\nHas this dataset already been used in AI or ML activities? Link to publications/reports.\nAre there recommendations on the intended use of the data, and uses that are not recommended? Yes / No/ Not applicable\n\n\n\n\n\nWhat is/are the major file formats? Pick from a list of common data formats/ “other” (choose all that apply)\n\nIs this format machine-readable? Yes / No / Not applicable\nIs the data available in at least one open, non-proprietary format? Yes / No / Not applicable\nAre there tools/services to support data format conversion? Yes / No\n\nIf so, provide the link to the tools/services\n\n\nData delivery:\n\nDoes data access require authentication (e.g., a registered user account)? Yes / No / Not applicable\nCan the file be accessed via direct file downloading or ordering? Yes / No / Not applicable\nIs there an Application Programming Interface (API) or web service to access the data? Yes / No / Not applicable\nIf there is an API, does the API follow an open standard protocol (e.g., OGC)? Yes / No\nIf there is an API, is there documentation for the API? Yes / No\n\nIf “Yes”, please provide a URL to the documentation.\n\nIs the data available publicly via cloud services? Yes / No / Not applicable\n\nFor restricted data, have measures been taken to provide some access while still applying appropriate protection for privacy and security? Yes / No / Not Applicable\n\nHas the data been aggregated to reduce granularity? Yes / No / Not applicable\nHas the data been anonymized / de-identified? Yes / No / Not applicable\nIs there secure access to the full dataset for authorized users? Yes / No / Not applicable\n\n\n\n\n\n\nHave null values/gaps been filled? Yes / No / Not applicable\nHave outliers been identified? Yes, tagged / Yes, removed / No / Not applicable\nIs the data gridded (regularly sampled in time and space)?\n\nOptions to choose from (choose all that apply):\n\nRegularly gridded in space / Constant time-frequency / Regularly gridded in space and constant time-frequency / Not gridded / Not applicable\n\nIf the data is gridded, was it transformed from a different original sampling? Yes, from irregular sampling / Yes, from a different regular sampling / No, this is the original sampling\nIf the data is resampled from the original sampling, is the data also available at the original sampling? Yes / No / Only available at request / Not applicable\n\nAre there associated targets or labels for supervised learning techniques (i.e., can this be used as a training dataset for supervised learning techniques)? Yes / No / Not applicable\n\nIf there are associated targets/labels, are community labeling standards implemented (e.g., STAC label extension, ESA AIREO specification, etc)?\n\nA list of label standards to choose from + “others” option\n\n\n\n\n\n\n\n\n\n\nCompleteness: the breadth of a dataset compared to an ideal 100% completion (spatial, temporal, demographic, etc.); important in avoiding sampling bias\nConsistency: uniformity within the entire dataset or compared with similar data collections; for example, no changes in units or data types over time; the item measured against itself or its a counterpart in another dataset or database\nBias: a systematic tilt in the dataset when compared to a reference, caused for example by instrumentation, incorrect data processing, unrepresentative sampling, or human error; the exact nature of bias and how it is measured will vary depending on the type of data and the research domain.\nUncertainty: parameter, associated with the result of a measurement, that characterizes the dispersion of the values that could reasonably be attributed to the measurand.\nTimeliness: the speed of data release, compared to when an event occurred or measurements were made; requirements will vary depending on the timeframe of the phenomenon (e.g., severe thunderstorms vs. climate change, or disease outbreaks vs. life expectancy trends)\nProvenance: identification of the data sources, how it was processed, and who released it.\nIntegrity: verification that the data remains unchanged from the original; aka data fixity.\n\n\n\n\n\nDataset Metadata: complete information about the dataset: quality, provenance, location, time period, responsible parties, purpose, etc.\nData Dictionary/Codebook: complete information about the individual variables / measures / parameters within a dataset: type, units, null value, etc.\nIdentifier: a code or number that uniquely identifies a dataset\nOntology: formalized definitions of concepts within a domain of knowledge, and the nature of the inter-relationships among those concepts\n\n\n\n\n\nFormats: standards that govern how information is stored in a computer file (e.g., CSV, JSON, GeoTIFF, etc.); different AI user communities will have different requirements, so the best practice is to provide several format options to meet the needs of multiple high priority user communities.\nDelivery Options: mechanisms for publishing open data for public use (e.g., direct file download, Application Programming Interface (API), cloud services, etc.); different AI user communities will have different requirements, so the best practice is to provide several delivery options to meet the needs of multiple high priority user communities.\nLicense/Usage Rights: information on who is allowed to use the data and for what purposes, including data sharing agreements, fees, etc.; some federal data needs to have restrictions and some will be fully open, so rights should be documented in detail\nSecurity/Privacy: protection of data that is restricted in some way (privacy, proprietary/business information, national security, etc.)\n\n\n\n\n\n\nOSTP Subcommittee on Open Science (2019), Draft AI-ready data matrix. (This draft document is not an official publication of the committee and can be requested for reference.)"
  },
  {
    "objectID": "guidelines/ai-ready-data-checklist-v.1.0.html#general-information",
    "href": "guidelines/ai-ready-data-checklist-v.1.0.html#general-information",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "Link to the dataset landing page (questions below could be automatically filled from the landing page in the future)\n\nName of the dataset\nThe current version of the dataset\nPoint of contact for the dataset\nWhen was the dataset originally published?\n\nIs this raw data or a derived/processed data product? Raw/Derived\nIs this observational data, simulation/model output, or synthetic data? Observed/Modeled/Synthetic\nIs the data single-source or aggregated from several sources? Single-source/Aggregated"
  },
  {
    "objectID": "guidelines/ai-ready-data-checklist-v.1.0.html#data-quality",
    "href": "guidelines/ai-ready-data-checklist-v.1.0.html#data-quality",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "Questions on timeliness:\n\nWill the dataset be updated? Yes, it will be updated. / No, it will not be updated\nIf the data will be updated, how often will it be updated? [choose from]\n\nUpdated when new data are added.\n\nChoose the update frequency that best describes the dataset: near-real-time (irregularly) / hourly or sub-hourly / daily or sub-daily / weekly / monthly / yearly / longer than a year\nWill there be different stages of the update (e.g., updated with preliminary data first and replaced by a later update of the full record)? Yes/No/Not applicable.\n\nIf yes, what is the delay between different stages? [short answer]\n\n\nUpdated when a new version of the dataset is available.\n\nShould the new version of the dataset supersede the current version? Yes / No / Others\n\nProvide an explanation for “Others”\n\n\n\n\nQuestions on data completeness\n\nIs there any documentation about the completeness of the dataset? Yes / No\n\nIf yes, link to the report/document\n\nHow complete is the dataset compared to the expected spatial coverage? Complete / Partial / Unknown / Not applicable\nHow complete is the dataset compared to the expected temporal coverage? Complete / Partial / Unknown / Not applicable\n\nQuestions on data consistency\n\nIs this dataset self-consistent in that its units, data types, and parameter names do not change over time and space? Yes / No / Not applicable\nIs this dataset’s units, data types, and parameter names consistent with similar data collections? Yes / No / Not applicable\nAre there processes to monitor for units, data types, and parameter consistency? Yes / No / Not applicable\n\nIf yes, what measures are taken? Manual review / Automated review\n\n\nQuestions on data bias\n\nIs there known bias in the dataset? Yes / No\n\nIf yes, provide more information\n\nHave measures been taken to examine bias? Yes / No\n\nIf yes, what measures were used?\nIs the bias metrological traceable?\n\nIs there reported bias in the data? No known bias / Bias found and reported / No information available\n\n(optional) Link to the report/document on the bias\n(optional) Link to tools available to reduce bias\n(optional) Link to a bias-corrected or bias-reduced version of the dataset\n\nIs there quantitative information about data resolution in space and time? Yes / No / Not applicable\nAre there published data quality procedures or reports? Yes / No\n\nIf there is published quality information, please provide the link to the information.\n\nIs the provenance of the dataset tracked and documented? Yes / No / Not applicable\nAre there checksums / other checks for data integrity? Yes / No / Not applicable\nWhat is the size of the dataset? Depending on the resource, this might be total data volume, dimensionality, number of images, data files, table rows, image size, etc. [Short Answer]"
  },
  {
    "objectID": "guidelines/ai-ready-data-checklist-v.1.0.html#data-documentation",
    "href": "guidelines/ai-ready-data-checklist-v.1.0.html#data-documentation",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "Does the dataset metadata follow a community/domain standard or convention? Yes / No / Not applicable\n\nIf the metadata follows a community/domain standard, which standard is it? Select from a list [CF, …, TBD, others]\nIs the dataset metadata machine-readable? Yes / No / Not applicable\nDoes it include details on the spatial and temporal extent? Yes / No / Not applicable\n\nIs there a comprehensive data dictionary/codebook that describes what each element of the dataset means? parameters? Yes / No / Not applicable\n\nIs the data dictionary standardized? Yes / No / Not applicable\nIs the data dictionary machine-readable? Yes / No / Not applicable\nDo the parameters follow a defined standard? Yes / No / Not applicable\n\nIf the parameters follow a defined standard, which standard it is?\n\nAre parameters crosswalked in an ontology or common vocabulary (e.g. NIEM)? Yes / No / Not applicable\n\nDoes the dataset have a unique persistent identifier, e.g. DOI? Yes, [supply identifier] / No / Not applicable\nIs there contact information for subject-matter experts? Yes / No / Not applicable\nIs there a mechanism for user feedback and suggestions? Yes / No / Not applicable\nAre there example codes/notebooks/toolkits available showing how the data can be used? Yes / No / Not applicable\nWhat is the license for the data?\n\nPick from a list of data licenses + others + no official data license\nIs the license standardized and machine-readable (e.g. Creative Commons)? Yes / No / Not applicable\n\nHas this dataset already been used in AI or ML activities? Link to publications/reports.\nAre there recommendations on the intended use of the data, and uses that are not recommended? Yes / No/ Not applicable"
  },
  {
    "objectID": "guidelines/ai-ready-data-checklist-v.1.0.html#data-access",
    "href": "guidelines/ai-ready-data-checklist-v.1.0.html#data-access",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "What is/are the major file formats? Pick from a list of common data formats/ “other” (choose all that apply)\n\nIs this format machine-readable? Yes / No / Not applicable\nIs the data available in at least one open, non-proprietary format? Yes / No / Not applicable\nAre there tools/services to support data format conversion? Yes / No\n\nIf so, provide the link to the tools/services\n\n\nData delivery:\n\nDoes data access require authentication (e.g., a registered user account)? Yes / No / Not applicable\nCan the file be accessed via direct file downloading or ordering? Yes / No / Not applicable\nIs there an Application Programming Interface (API) or web service to access the data? Yes / No / Not applicable\nIf there is an API, does the API follow an open standard protocol (e.g., OGC)? Yes / No\nIf there is an API, is there documentation for the API? Yes / No\n\nIf “Yes”, please provide a URL to the documentation.\n\nIs the data available publicly via cloud services? Yes / No / Not applicable\n\nFor restricted data, have measures been taken to provide some access while still applying appropriate protection for privacy and security? Yes / No / Not Applicable\n\nHas the data been aggregated to reduce granularity? Yes / No / Not applicable\nHas the data been anonymized / de-identified? Yes / No / Not applicable\nIs there secure access to the full dataset for authorized users? Yes / No / Not applicable"
  },
  {
    "objectID": "guidelines/ai-ready-data-checklist-v.1.0.html#data-preparation",
    "href": "guidelines/ai-ready-data-checklist-v.1.0.html#data-preparation",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "Have null values/gaps been filled? Yes / No / Not applicable\nHave outliers been identified? Yes, tagged / Yes, removed / No / Not applicable\nIs the data gridded (regularly sampled in time and space)?\n\nOptions to choose from (choose all that apply):\n\nRegularly gridded in space / Constant time-frequency / Regularly gridded in space and constant time-frequency / Not gridded / Not applicable\n\nIf the data is gridded, was it transformed from a different original sampling? Yes, from irregular sampling / Yes, from a different regular sampling / No, this is the original sampling\nIf the data is resampled from the original sampling, is the data also available at the original sampling? Yes / No / Only available at request / Not applicable\n\nAre there associated targets or labels for supervised learning techniques (i.e., can this be used as a training dataset for supervised learning techniques)? Yes / No / Not applicable\n\nIf there are associated targets/labels, are community labeling standards implemented (e.g., STAC label extension, ESA AIREO specification, etc)?\n\nA list of label standards to choose from + “others” option"
  },
  {
    "objectID": "guidelines/ai-ready-data-checklist-v.1.0.html#appendix---definition-of-terms-used-in-the-checklist",
    "href": "guidelines/ai-ready-data-checklist-v.1.0.html#appendix---definition-of-terms-used-in-the-checklist",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "Completeness: the breadth of a dataset compared to an ideal 100% completion (spatial, temporal, demographic, etc.); important in avoiding sampling bias\nConsistency: uniformity within the entire dataset or compared with similar data collections; for example, no changes in units or data types over time; the item measured against itself or its a counterpart in another dataset or database\nBias: a systematic tilt in the dataset when compared to a reference, caused for example by instrumentation, incorrect data processing, unrepresentative sampling, or human error; the exact nature of bias and how it is measured will vary depending on the type of data and the research domain.\nUncertainty: parameter, associated with the result of a measurement, that characterizes the dispersion of the values that could reasonably be attributed to the measurand.\nTimeliness: the speed of data release, compared to when an event occurred or measurements were made; requirements will vary depending on the timeframe of the phenomenon (e.g., severe thunderstorms vs. climate change, or disease outbreaks vs. life expectancy trends)\nProvenance: identification of the data sources, how it was processed, and who released it.\nIntegrity: verification that the data remains unchanged from the original; aka data fixity.\n\n\n\n\n\nDataset Metadata: complete information about the dataset: quality, provenance, location, time period, responsible parties, purpose, etc.\nData Dictionary/Codebook: complete information about the individual variables / measures / parameters within a dataset: type, units, null value, etc.\nIdentifier: a code or number that uniquely identifies a dataset\nOntology: formalized definitions of concepts within a domain of knowledge, and the nature of the inter-relationships among those concepts\n\n\n\n\n\nFormats: standards that govern how information is stored in a computer file (e.g., CSV, JSON, GeoTIFF, etc.); different AI user communities will have different requirements, so the best practice is to provide several format options to meet the needs of multiple high priority user communities.\nDelivery Options: mechanisms for publishing open data for public use (e.g., direct file download, Application Programming Interface (API), cloud services, etc.); different AI user communities will have different requirements, so the best practice is to provide several delivery options to meet the needs of multiple high priority user communities.\nLicense/Usage Rights: information on who is allowed to use the data and for what purposes, including data sharing agreements, fees, etc.; some federal data needs to have restrictions and some will be fully open, so rights should be documented in detail\nSecurity/Privacy: protection of data that is restricted in some way (privacy, proprietary/business information, national security, etc.)"
  },
  {
    "objectID": "guidelines/ai-ready-data-checklist-v.1.0.html#references",
    "href": "guidelines/ai-ready-data-checklist-v.1.0.html#references",
    "title": "AI Ready Checklist",
    "section": "",
    "text": "OSTP Subcommittee on Open Science (2019), Draft AI-ready data matrix. (This draft document is not an official publication of the committee and can be requested for reference.)"
  },
  {
    "objectID": "datasets/nesdis_ease2_latlon_1k/logs.html",
    "href": "datasets/nesdis_ease2_latlon_1k/logs.html",
    "title": "Logs: nesdis_ease2_latlon_nhem_1k, nesdis_ease2_latlon_shem_1k",
    "section": "",
    "text": "Logs: nesdis_ease2_latlon_nhem_1k, nesdis_ease2_latlon_shem_1k\n\n\n\nDate Logged\nDates Affected\nData Status\nAdditional Note\n\n\n\n\n04/18/2024\n04/18/2024\navailable\nuploaded"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/logs.html",
    "href": "datasets/nesdis_blendedsic_nhem_daily/logs.html",
    "title": "Logs: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "Logs: nesdis_blendedsic_nhem_daily\n\n\n\n\n\n\n\n\n\nDate Logged\nDates Affected\nData Status\nAdditional Note\n\n\n\n\n03/20/2024\n03/17/2024-03/24/2024\nmissing\norbit rephasing effort\n\n\n08/08/2024\n08/08/2024\navailable\nERDDAP metadata projection attributes modified"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html",
    "href": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html",
    "title": "AI-Ready: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "Link to Data Landing Page\n\nName : Blended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Arctic\nVersion : 1.0\nContact : Richard Dworak\nData Published : 12/18/2023\n\nIs this raw data or a derived/processed data product? Derived\nIs this observational data, simulation/model output, or synthetic data? Observational\nIs the data single-source or aggregated from several sources? Aggregated\n\n\n\n\n\nTimeliness:\n\nWill the dataset be updated? Yes, it will be updated. \n\nUpdated when new data are added daily\nWill there be different stages of the update? No\n\n\nData completeness\n\nIs there any documentation about the completeness of the dataset? Yes\n\nlink to documentation\n\nHow complete is the dataset compared to the expected spatial coverage? Complete\nHow complete is the dataset compared to the expected temporal coverage? Complete\n\nData consistency\n\nIs this dataset self-consistent in that its units, data types, and parameter names do not change over time and space? Yes\nIs this dataset’s units, data types, and parameter names consistent with similar data collections? Yes\nAre there processes to monitor for units, data types, and parameter consistency? No\n\nIf yes, what measures are taken? Manual review [TODO]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nCheck for pole hole, flag values?\nData consistency: create data management plan and add review process\n\n\n\n\nData bias\n\nIs there known bias in the dataset? No\n\nlink to documentation\n\nHave measures been taken to examine bias? No\nIs there reported bias in the data? No known bias\nIs there quantitative information about data resolution in space and time? Yes\nAre there published data quality procedures or reports? No\nIs the provenance of the dataset tracked and documented? No\nAre there checksums / other checks for data integrity? No\nWhat is the size of the dataset? Depending on the resource, this might be total data volume, dimensionality, number of images, data files, table rows, image size, etc. _ approximately 15 ~ 540 MB (file size per day)_\n\n\n\n\n\n\nDoes the dataset metadata follow a community/domain standard or convention? Yes\n\nIf the metadata follows a community/domain standard, which standard is it? CF-1.6, ACDD-1.3, NOAA CDR v1.0, GDS v2.0, COARDS\nIs the dataset metadata machine-readable? Yes\nDoes it include details on the spatial and temporal extent? Yes\n\nIs there a comprehensive data dictionary/codebook that describes what each element of the dataset means? parameters? Yes\n\nIs the data dictionary standardized? Yes\nIs the data dictionary machine-readable? Yes\nDo the parameters follow a defined standard? Yes\n\nIf the parameters follow a defined standard, which standard it is? CF-1.6\n\nAre parameters crosswalked in an ontology or common vocabulary (e.g. NIEM)? Not applicable\n\nDoes the dataset have a unique persistent identifier, e.g. DOI? Yes (CHECK DOI)\nIs there contact information for subject-matter experts? Yes\nIs there a mechanism for user feedback and suggestions? Yes\nAre there example codes/notebooks/toolkits available showing how the data can be used? Yes\nWhat is the license for the data?\n\nNCEI Data Licensing These data may be redistributed and used without restriction\nIs the license standardized and machine-readable (e.g. Creative Commons)? Yes\n\nHas this dataset already been used in AI or ML activities? No\nAre there recommendations on the intended use of the data, and uses that are not recommended? Yes [TODO: link to documentation]\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nWhat is/are the major file formats? netcdf\n\nIs this format machine-readable? Yes\nIs the data available in at least one open, non-proprietary format? Yes\nAre there tools/services to support data format conversion? Yes\n\nIf so, provide the link to the tools/services\n\n\nData delivery: ERDDAP\n\nDoes data access require authentication (e.g., a registered user account)? No\nCan the file be accessed via direct file downloading or ordering? Yes\nIs there an Application Programming Interface (API) or web service to access the data? Yes\nIf there is an API, does the API follow an open standard protocol (e.g., OGC)? Yes\nIf there is an API, is there documentation for the API? Yes\n\nIf “Yes”, please provide a URL to the documentation.\n\nIs the data available publicly via cloud services? Yes\n\nFor restricted data, have measures been taken to provide some access while still applying appropriate protection for privacy and security? Yes\n\nHas the data been aggregated to reduce granularity? Yes\nHas the data been anonymized / de-identified? Not applicable\nIs there secure access to the full dataset for authorized users? No\n\n\n\n\n\n\nHave null values/gaps been filled? Yes\nHave outliers been identified? No\nIs the data gridded (regularly sampled in time and space)? Yes\n\nRegularly gridded in space and constant time-frequency\nIf the data is gridded, was it transformed from a different original sampling? Yes, from a different regular sampling\nIf the data is resampled from the original sampling, is the data also available at the original sampling? Yes\n\nAre there associated targets or labels for supervised learning techniques (i.e., can this be used as a training dataset for supervised learning techniques)? Yes\n\n\n\n\n\nPolarWatch Metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_nhem_daily/index.html"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#general-information",
    "href": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#general-information",
    "title": "AI-Ready: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "Link to Data Landing Page\n\nName : Blended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Arctic\nVersion : 1.0\nContact : Richard Dworak\nData Published : 12/18/2023\n\nIs this raw data or a derived/processed data product? Derived\nIs this observational data, simulation/model output, or synthetic data? Observational\nIs the data single-source or aggregated from several sources? Aggregated"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#data-quality",
    "href": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#data-quality",
    "title": "AI-Ready: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "Timeliness:\n\nWill the dataset be updated? Yes, it will be updated. \n\nUpdated when new data are added daily\nWill there be different stages of the update? No\n\n\nData completeness\n\nIs there any documentation about the completeness of the dataset? Yes\n\nlink to documentation\n\nHow complete is the dataset compared to the expected spatial coverage? Complete\nHow complete is the dataset compared to the expected temporal coverage? Complete\n\nData consistency\n\nIs this dataset self-consistent in that its units, data types, and parameter names do not change over time and space? Yes\nIs this dataset’s units, data types, and parameter names consistent with similar data collections? Yes\nAre there processes to monitor for units, data types, and parameter consistency? No\n\nIf yes, what measures are taken? Manual review [TODO]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nCheck for pole hole, flag values?\nData consistency: create data management plan and add review process\n\n\n\n\nData bias\n\nIs there known bias in the dataset? No\n\nlink to documentation\n\nHave measures been taken to examine bias? No\nIs there reported bias in the data? No known bias\nIs there quantitative information about data resolution in space and time? Yes\nAre there published data quality procedures or reports? No\nIs the provenance of the dataset tracked and documented? No\nAre there checksums / other checks for data integrity? No\nWhat is the size of the dataset? Depending on the resource, this might be total data volume, dimensionality, number of images, data files, table rows, image size, etc. _ approximately 15 ~ 540 MB (file size per day)_"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#data-documentation",
    "href": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#data-documentation",
    "title": "AI-Ready: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "Does the dataset metadata follow a community/domain standard or convention? Yes\n\nIf the metadata follows a community/domain standard, which standard is it? CF-1.6, ACDD-1.3, NOAA CDR v1.0, GDS v2.0, COARDS\nIs the dataset metadata machine-readable? Yes\nDoes it include details on the spatial and temporal extent? Yes\n\nIs there a comprehensive data dictionary/codebook that describes what each element of the dataset means? parameters? Yes\n\nIs the data dictionary standardized? Yes\nIs the data dictionary machine-readable? Yes\nDo the parameters follow a defined standard? Yes\n\nIf the parameters follow a defined standard, which standard it is? CF-1.6\n\nAre parameters crosswalked in an ontology or common vocabulary (e.g. NIEM)? Not applicable\n\nDoes the dataset have a unique persistent identifier, e.g. DOI? Yes (CHECK DOI)\nIs there contact information for subject-matter experts? Yes\nIs there a mechanism for user feedback and suggestions? Yes\nAre there example codes/notebooks/toolkits available showing how the data can be used? Yes\nWhat is the license for the data?\n\nNCEI Data Licensing These data may be redistributed and used without restriction\nIs the license standardized and machine-readable (e.g. Creative Commons)? Yes\n\nHas this dataset already been used in AI or ML activities? No\nAre there recommendations on the intended use of the data, and uses that are not recommended? Yes [TODO: link to documentation]\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nWhat is/are the major file formats? netcdf\n\nIs this format machine-readable? Yes\nIs the data available in at least one open, non-proprietary format? Yes\nAre there tools/services to support data format conversion? Yes\n\nIf so, provide the link to the tools/services\n\n\nData delivery: ERDDAP\n\nDoes data access require authentication (e.g., a registered user account)? No\nCan the file be accessed via direct file downloading or ordering? Yes\nIs there an Application Programming Interface (API) or web service to access the data? Yes\nIf there is an API, does the API follow an open standard protocol (e.g., OGC)? Yes\nIf there is an API, is there documentation for the API? Yes\n\nIf “Yes”, please provide a URL to the documentation.\n\nIs the data available publicly via cloud services? Yes\n\nFor restricted data, have measures been taken to provide some access while still applying appropriate protection for privacy and security? Yes\n\nHas the data been aggregated to reduce granularity? Yes\nHas the data been anonymized / de-identified? Not applicable\nIs there secure access to the full dataset for authorized users? No\n\n\n\n\n\n\nHave null values/gaps been filled? Yes\nHave outliers been identified? No\nIs the data gridded (regularly sampled in time and space)? Yes\n\nRegularly gridded in space and constant time-frequency\nIf the data is gridded, was it transformed from a different original sampling? Yes, from a different regular sampling\nIf the data is resampled from the original sampling, is the data also available at the original sampling? Yes\n\nAre there associated targets or labels for supervised learning techniques (i.e., can this be used as a training dataset for supervised learning techniques)? Yes\n\n\n\n\n\nPolarWatch Metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_nhem_daily/index.html"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#data-access",
    "href": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#data-access",
    "title": "AI-Ready: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "What is/are the major file formats? netcdf\n\nIs this format machine-readable? Yes\nIs the data available in at least one open, non-proprietary format? Yes\nAre there tools/services to support data format conversion? Yes\n\nIf so, provide the link to the tools/services\n\n\nData delivery: ERDDAP\n\nDoes data access require authentication (e.g., a registered user account)? No\nCan the file be accessed via direct file downloading or ordering? Yes\nIs there an Application Programming Interface (API) or web service to access the data? Yes\nIf there is an API, does the API follow an open standard protocol (e.g., OGC)? Yes\nIf there is an API, is there documentation for the API? Yes\n\nIf “Yes”, please provide a URL to the documentation.\n\nIs the data available publicly via cloud services? Yes\n\nFor restricted data, have measures been taken to provide some access while still applying appropriate protection for privacy and security? Yes\n\nHas the data been aggregated to reduce granularity? Yes\nHas the data been anonymized / de-identified? Not applicable\nIs there secure access to the full dataset for authorized users? No"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#data-preparation",
    "href": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#data-preparation",
    "title": "AI-Ready: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "Have null values/gaps been filled? Yes\nHave outliers been identified? No\nIs the data gridded (regularly sampled in time and space)? Yes\n\nRegularly gridded in space and constant time-frequency\nIf the data is gridded, was it transformed from a different original sampling? Yes, from a different regular sampling\nIf the data is resampled from the original sampling, is the data also available at the original sampling? Yes\n\nAre there associated targets or labels for supervised learning techniques (i.e., can this be used as a training dataset for supervised learning techniques)? Yes"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#additional-metadata",
    "href": "datasets/nesdis_blendedsic_nhem_daily/ai-ready.html#additional-metadata",
    "title": "AI-Ready: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "PolarWatch Metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_nhem_daily/index.html"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/logs.html",
    "href": "datasets/nesdis_blendedsic_shem_daily/logs.html",
    "title": "Logs: nesdis_blendedsic_nhem_daily",
    "section": "",
    "text": "Logs: nesdis_blendedsic_nhem_daily\n\n\n\n\n\n\n\n\n\nDate Logged\nDates Affected\nData Status\nAdditional Note\n\n\n\n\n03/20/2024\n03/17/2024-03/24/2024\nmissing\norbit rephasing effort\n\n\n08/08/2024\n08/08/2024\navailable\nERDDAP metadata projection attributes modified"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html",
    "href": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html",
    "title": "Dataset ID: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "Link to Data Landing Page\n\nName : Blended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Antarctic\nVersion : 1.0\nContact : Richard Dworak\nData Published : 12/18/2023\n\nIs this raw data or a derived/processed data product? Derived\nIs this observational data, simulation/model output, or synthetic data? Synthetic\nIs the data single-source or aggregated from several sources? Aggregated\n\n\n\n\n\nTimeliness:\n\nWill the dataset be updated? Yes, it will be updated. \n\nUpdated when new data are added daily\nWill there be different stages of the update? No\n\n\nData completeness\n\nIs there any documentation about the completeness of the dataset? Yes\n\nlink to documentation\n\nHow complete is the dataset compared to the expected spatial coverage? Complete\nHow complete is the dataset compared to the expected temporal coverage? Complete\n\nData consistency\n\nIs this dataset self-consistent in that its units, data types, and parameter names do not change over time and space? Yes\nIs this dataset’s units, data types, and parameter names consistent with similar data collections? Yes\nAre there processes to monitor for units, data types, and parameter consistency? No\n\nIf yes, what measures are taken? Manual review [TODO]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nCheck for pole hole, flag values?\nData consistency: create data management plan and add review process\n\n\n\n\nData bias\n\nIs there known bias in the dataset? No\n\nlink to documentation\n\nHave measures been taken to examine bias? No\nIs there reported bias in the data? No known bias\nIs there quantitative information about data resolution in space and time? Yes\nAre there published data quality procedures or reports? No\nIs the provenance of the dataset tracked and documented? No\nAre there checksums / other checks for data integrity? No\nWhat is the size of the dataset? Depending on the resource, this might be total data volume, dimensionality, number of images, data files, table rows, image size, etc. _ approximately 15 ~ 540 MB (file size per day)_\n\n\n\n\n\n\nDoes the dataset metadata follow a community/domain standard or convention? Yes\n\nIf the metadata follows a community/domain standard, which standard is it? CF-1.6, ACDD-1.3, NOAA CDR v1.0, GDS v2.0, COARDS\nIs the dataset metadata machine-readable? Yes\nDoes it include details on the spatial and temporal extent? Yes\n\nIs there a comprehensive data dictionary/codebook that describes what each element of the dataset means? parameters? Yes\n\nIs the data dictionary standardized? Yes\nIs the data dictionary machine-readable? Yes\nDo the parameters follow a defined standard? Yes\n\nIf the parameters follow a defined standard, which standard it is? CF-1.6\n\nAre parameters crosswalked in an ontology or common vocabulary (e.g. NIEM)? Not applicable\n\nDoes the dataset have a unique persistent identifier, e.g. DOI? Yes (CHECK DOI)\nIs there contact information for subject-matter experts? Yes\nIs there a mechanism for user feedback and suggestions? Yes\nAre there example codes/notebooks/toolkits available showing how the data can be used? Yes\nWhat is the license for the data?\n\nNCEI Data Licensing These data may be redistributed and used without restriction\nIs the license standardized and machine-readable (e.g. Creative Commons)? Yes\n\nHas this dataset already been used in AI or ML activities? No\nAre there recommendations on the intended use of the data, and uses that are not recommended? Yes [TODO: link to documentation]\n\n\n\n\n\nWhat is/are the major file formats? netcdf\n\nIs this format machine-readable? Yes\nIs the data available in at least one open, non-proprietary format? Yes\nAre there tools/services to support data format conversion? Yes\n\nIf so, provide the link to the tools/services\n\n\nData delivery: ERDDAP\n\nDoes data access require authentication (e.g., a registered user account)? No\nCan the file be accessed via direct file downloading or ordering? Yes\nIs there an Application Programming Interface (API) or web service to access the data? Yes\nIf there is an API, does the API follow an open standard protocol (e.g., OGC)? Yes\nIf there is an API, is there documentation for the API? Yes\n\nIf “Yes”, please provide a URL to the documentation.\n\nIs the data available publicly via cloud services? Yes\n\nFor restricted data, have measures been taken to provide some access while still applying appropriate protection for privacy and security? Yes\n\nHas the data been aggregated to reduce granularity? Yes\nHas the data been anonymized / de-identified? Not applicable\nIs there secure access to the full dataset for authorized users? No\n\n\n\n\n\n\nHave null values/gaps been filled? Yes\nHave outliers been identified? No\nIs the data gridded (regularly sampled in time and space)? Yes\n\nRegularly gridded in space and constant time-frequency\nIf the data is gridded, was it transformed from a different original sampling? Yes, from a different regular sampling\nIf the data is resampled from the original sampling, is the data also available at the original sampling? Yes\n\nAre there associated targets or labels for supervised learning techniques (i.e., can this be used as a training dataset for supervised learning techniques)? Yes\n\n\n\n\n\nPolarWatch Metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_shem_daily/index.html"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#general-information",
    "href": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#general-information",
    "title": "Dataset ID: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "Link to Data Landing Page\n\nName : Blended Sea Ice Concentration from AMSR2/VIIRS Daily 1km, Antarctic\nVersion : 1.0\nContact : Richard Dworak\nData Published : 12/18/2023\n\nIs this raw data or a derived/processed data product? Derived\nIs this observational data, simulation/model output, or synthetic data? Synthetic\nIs the data single-source or aggregated from several sources? Aggregated"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#data-quality",
    "href": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#data-quality",
    "title": "Dataset ID: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "Timeliness:\n\nWill the dataset be updated? Yes, it will be updated. \n\nUpdated when new data are added daily\nWill there be different stages of the update? No\n\n\nData completeness\n\nIs there any documentation about the completeness of the dataset? Yes\n\nlink to documentation\n\nHow complete is the dataset compared to the expected spatial coverage? Complete\nHow complete is the dataset compared to the expected temporal coverage? Complete\n\nData consistency\n\nIs this dataset self-consistent in that its units, data types, and parameter names do not change over time and space? Yes\nIs this dataset’s units, data types, and parameter names consistent with similar data collections? Yes\nAre there processes to monitor for units, data types, and parameter consistency? No\n\nIf yes, what measures are taken? Manual review [TODO]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nCheck for pole hole, flag values?\nData consistency: create data management plan and add review process\n\n\n\n\nData bias\n\nIs there known bias in the dataset? No\n\nlink to documentation\n\nHave measures been taken to examine bias? No\nIs there reported bias in the data? No known bias\nIs there quantitative information about data resolution in space and time? Yes\nAre there published data quality procedures or reports? No\nIs the provenance of the dataset tracked and documented? No\nAre there checksums / other checks for data integrity? No\nWhat is the size of the dataset? Depending on the resource, this might be total data volume, dimensionality, number of images, data files, table rows, image size, etc. _ approximately 15 ~ 540 MB (file size per day)_"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#data-documentation",
    "href": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#data-documentation",
    "title": "Dataset ID: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "Does the dataset metadata follow a community/domain standard or convention? Yes\n\nIf the metadata follows a community/domain standard, which standard is it? CF-1.6, ACDD-1.3, NOAA CDR v1.0, GDS v2.0, COARDS\nIs the dataset metadata machine-readable? Yes\nDoes it include details on the spatial and temporal extent? Yes\n\nIs there a comprehensive data dictionary/codebook that describes what each element of the dataset means? parameters? Yes\n\nIs the data dictionary standardized? Yes\nIs the data dictionary machine-readable? Yes\nDo the parameters follow a defined standard? Yes\n\nIf the parameters follow a defined standard, which standard it is? CF-1.6\n\nAre parameters crosswalked in an ontology or common vocabulary (e.g. NIEM)? Not applicable\n\nDoes the dataset have a unique persistent identifier, e.g. DOI? Yes (CHECK DOI)\nIs there contact information for subject-matter experts? Yes\nIs there a mechanism for user feedback and suggestions? Yes\nAre there example codes/notebooks/toolkits available showing how the data can be used? Yes\nWhat is the license for the data?\n\nNCEI Data Licensing These data may be redistributed and used without restriction\nIs the license standardized and machine-readable (e.g. Creative Commons)? Yes\n\nHas this dataset already been used in AI or ML activities? No\nAre there recommendations on the intended use of the data, and uses that are not recommended? Yes [TODO: link to documentation]"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#data-access",
    "href": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#data-access",
    "title": "Dataset ID: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "What is/are the major file formats? netcdf\n\nIs this format machine-readable? Yes\nIs the data available in at least one open, non-proprietary format? Yes\nAre there tools/services to support data format conversion? Yes\n\nIf so, provide the link to the tools/services\n\n\nData delivery: ERDDAP\n\nDoes data access require authentication (e.g., a registered user account)? No\nCan the file be accessed via direct file downloading or ordering? Yes\nIs there an Application Programming Interface (API) or web service to access the data? Yes\nIf there is an API, does the API follow an open standard protocol (e.g., OGC)? Yes\nIf there is an API, is there documentation for the API? Yes\n\nIf “Yes”, please provide a URL to the documentation.\n\nIs the data available publicly via cloud services? Yes\n\nFor restricted data, have measures been taken to provide some access while still applying appropriate protection for privacy and security? Yes\n\nHas the data been aggregated to reduce granularity? Yes\nHas the data been anonymized / de-identified? Not applicable\nIs there secure access to the full dataset for authorized users? No"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#data-preparation",
    "href": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#data-preparation",
    "title": "Dataset ID: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "Have null values/gaps been filled? Yes\nHave outliers been identified? No\nIs the data gridded (regularly sampled in time and space)? Yes\n\nRegularly gridded in space and constant time-frequency\nIf the data is gridded, was it transformed from a different original sampling? Yes, from a different regular sampling\nIf the data is resampled from the original sampling, is the data also available at the original sampling? Yes\n\nAre there associated targets or labels for supervised learning techniques (i.e., can this be used as a training dataset for supervised learning techniques)? Yes"
  },
  {
    "objectID": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#additional-metadata",
    "href": "datasets/nesdis_blendedsic_shem_daily/ai-ready.html#additional-metadata",
    "title": "Dataset ID: nesdis_blendedsic_shem_daily",
    "section": "",
    "text": "PolarWatch Metadata: https://polarwatch.noaa.gov/erddap/info/nesdis_blendedsic_shem_daily/index.html"
  },
  {
    "objectID": "meta_proj.html",
    "href": "meta_proj.html",
    "title": "Metadata",
    "section": "",
    "text": "Note\n\n\n\nFor projection information\n\n\n\nin NetCDF\ngrid_mapping = “NAME OF VARIABLE THAT HAS PROJ INFO”\n\n\nExample\nseaiceconc :grid_mapping = “projection”\nprojection :srid = “EPSG:3413”\nhttps://spatialreference.org/"
  },
  {
    "objectID": "index copy.html",
    "href": "index copy.html",
    "title": "PolarWatch Metadata",
    "section": "",
    "text": "Note\n\n\n\nThis document is a working copy.\n\n\nThis repository serves as a place to share data management workflow and guidelines for data (and metadata) products intended for hosting on the PolarWatch ERDDAP Server.\n\nData Management\nThe objective of PolarWatch is to disseminate remote sensing data, ensuring they are readily available. Consequently, the PolarWatch DMP focuses on aspects of the data lifecycle pertinent to its operations, such as data ingestion, processing, quality control, and management.\n\n\n\n\n\nflowchart LR\n  A(Get Data from Source) --&gt;B(Process, Q/C Data)\n  A --&gt; D(Create Metadata)\n  B --&gt; C(Store Data)\n  C --&gt; G(Backup Data)\n  B --&gt; D(Create Metadata)\n  C --&gt; F(Make Data Accessible)\n  D --&gt; F\n\n\n\n\n\n\nDiagram: General PolarWatch data workflow\nThe DMP Page provides an overview of the DMP components along with their detailed descriptions.\n\n\nAI-Ready Checklist\nThis checklist is developed through a collaboration of ESIP Data Readiness Cluster members include representatives from NOAA, NASA, USGS, and other organizations. The checklist will be updated periodically to reflect community feedback. The checklist aims to provide comprehensive metadata to support AI-ready research.\nsource: https://github.com/ESIPFed/data-readiness/blob/main/checklist-published/ai-ready-data-checklist-v.1.0.md\n\n\nData List\nThe Data List page presents a catalog of PolarWatch data products, including links to their respective DMP and AI-Ready documentation."
  }
]